# プロダクションレディマイクロサービス  
## マイクロサービスエコシステム  
マイクロサービスが正しく稼働し続ける環境（エコシステム）は4つのレイヤで構成される  
```
レイヤ1：ハードウェアレイヤ  
レイヤ2：通信  
レイヤ3：マイクロサービスプラットフォーム  
レイヤ4：マイクロサービス   
```

```
レイヤ1：物理サーバ、データベース、OS、リソース分離（仮想化・抽象化レイヤ）、構成管理、ホストレベルの監視、ホストレベルのロギング  
レイヤ2：ネットワーク、DNS、RPC、エンドポイント、メッセージング、サービス検出、サービスレジストリ、負荷分散  
レイヤ3：セルフサービス内部ツール、開発環境、テスト/パッケージング/ビルド/リリース用ツール、デプロイパイプライン、マイクロサービスのロギング、マイクロサービスレベルの監視  
レイヤ4：マイクロサービス、マイクロサービス固有の構成情報  
```

上位のレイヤの仕事をするエンジニアが、自分よりも下のレイヤの何かを設定、構成、利用しなければならないときは、そのエンジニアが使えるセルフサービスツールを用意すること。  
そうしなければ他のレイヤについてのエキスパートになることを求められ、大抵ミスが多発する。  
エキスパートでなくても利用できるようなUIを提供すること。  
  
マイクロサービス固有の構成情報（chefの設定、サーバー台数、デプロイツールの指定）などはマイクロサービス側（ソースコードの一部）に持つこと。  
そうしなければ何百ものマイクロサービス 固有の設定を下位レイヤが保持しなければならなくなる。  
  
## マイクロサービスのメリット  
スケーラビリティ（スケールアウトのしやすさ）  
処理効率（必要な機能を必要なだけスケールアウト・アップできる）  
開発効率（独立したデプロイ、機能追加のしやすさ）  
新テクノロジーへの対応  
  
## マイクロサービスのデメリット  
逆コンウェイの法則によるチーム孤立化（システム全体像を把握できる人が少なくなる）  
技術的スプロール（個々のマイクロサービスエコシステムが乱立する、開発スピードの速さから技術的負債が増える）  
障害の種類の増加  
リソースの奪い合い  

## マイクロサービスの標準化  
マイクロサービスには、すべてのマイクロサービスに適用できるほど一般的でありながら、  
定量化でき、測定可能な結果を生み出せる程度には個別的な標準と要件を定義しなければならない。  
  
マイクロサービスが標準を満たすための原則は  
マイクロサービスのアーキテクチャをどのように決め、どのように構築、実行すべきかを指導してくれるものである。  
  
原則のない標準は無意味である。  
  
## ・本番対応の標準  
マイクロサービスが満たすべき標準として「本番対応」というものがある。  
本番対応を満たすための原則が8つある。  
```  
1. 安定性  
2. 信頼性  
3. スケーラビリティ  
4. 耐障害性  
5. 大惨事対応  
6. パフォーマンス  
7. 監視  
8. ドキュメント  
```  
 
原則にはいくつか要件がある。  
それらの要件を満たすことで原則に従う。  

## 安定性と信頼性  
<details>  
  <summary>安定性・信頼性のあるマイクロサービスの特徴</summary>  

```  
・標準化された開発サイクルがある。  
・コードは、lintテスト、単体テスト、統合テスト、エンドツーエンドテストを通じて徹底的にテストされている。  
・テスト、パッケージング、ビルド、リリースプロセスが、完全に自動化されている。  
・ステージング、カナリア、本番のフェーズを備えた標準的なデプロイパイプラインがある。  
・クライアントがわかっている。  
・依存関係がわかっており、障害が起こったときのために、バックアップ、代替サービス、フォールバック、キャッシュが用意されている。  
・安定性、信頼性のあるルーティング、検出が備わっている。  
```  
  
</details>  
  
<details>  
  <summary>要件</summary>  
    
### ・開発サイクル  
前提としてバージョン管理システムを用いること。  
以下の手順で開発すること。  
```  
（1）コードを変更し開発環境(localhost, 開発用サーバー)で単体テスト、統合テストを行い問題なければ中央リポジトリにコミットする。  
（2）新しいビルドがlintテスト、単体テスト、統合テスト（、エンドツーエンドテスト）に合格したら、レビューを行う。  
（3）中央リポジトリに変更をマージする。  
（4）新しいビルドをデプロイパイプラインに送る。  
（5）(1)に戻る。  
```  
  
### ・デプロイパイプライン  
デプロイプロセスを技術組織全体で標準化したデプロイパイプラインを導入し、ヒューマンエラーを取り除くこと。  
パイプラインは、ステージング→カナリア→本番の順にデプロイを強制すること。  
ステージング環境は、完全ステージングか部分ステージングのどちらかとする。  
```  
完全ステージング... 本番環境との接続を一切許さない。他のマイクロサービスのステージング環境によっては正しくテストできない可能性があるため、デプロイを調整、スケジューリングする必要がある。  
部分ステージング... 本番環境へのアクセスが可能。不具合のあるコードがステージングにデプロイされたとき本番環境に影響が及ぶ可能性があるため、自動ロールバック機能を必要性がある。  
```  
ステージングには本番トラフィックは流さない。  
  
カナリアは、本番トラフィックを実行する小さなサーバプール（本番の処理能力の5%〜10%）に新ビルドをデプロイする。  
カナリアホストは本番サーバプールからランダムに選ぶ必要がある。  
アラートやログは本番環境と区別できなければならない。  
  
### ・依存関係  
安定性、信頼性を備えたマイクロサービスを作るには、依存関係の障害の影響を緩和する必要がある。  
したがって  
マイクロサービスのSLAを損なう可能性のある依存関係を把握すること。  
その依存関係をアーキテクチャ図とドキュメントに含め（ドキュメントの原則）、  
サービスのダッシュボードに含めなければならない。（監視の原則）  
  
次に個々の依存関係の障害時の対応として  
```  
（1）バックアップ... リクエストした内容や取得結果のバックアップ  
（2）代替サービス... 代わりのサービスの呼び出し  
（3）フォールバック... 機能を制限して稼働  
（4）キャッシュ... 取得結果のキャッシュ  
```  
のどれかを設定すること。  
  
### ・ルーティングと検出  
マイクロサービスエコシステムのレイヤ2（通信レイヤ）で安定性と信頼性が関係するのは、サービス検出、サービスレジストリ、負荷分散である。  
これらの機能で、マイクロサービスの健全性チェックを行うこと。  
定期的にヘルスチェックをリクエストしたり、多数の未処理例外を検知したら起動するサーキットブレーカーを配置すること。  
  
### ・非推奨と廃止  
マイクロサービスのエンドポイントを廃止するときには、そのサービスの開発チームは全てのクライアントサービスに警告メッセージを送り、  
依存関係の廃止にどのように対応すべきかアドバイスすること。  
エンドポイントを非推奨にする場合も同様である。  
  
</details>  

### 安定性・信頼性の評価基準  
```  
【開発サイクル】  
・マイクロサービスは、全てのコードが格納される一元管理されたリポジトリを持っているか。  
・開発者は、本番環境の状態（例えば、現実の世界）を正確に反映している開発環境で作業をしているか。  
・マイクロサービス のための適切なlintテスト、単体テスト、結合テスト、エンドツーエンドテストは揃っているか。  
・コードレビューの手続きや方針を用意してあるか。  
・テスト、パッケージング、ビルド、リリースのプロセスは自動化されているか。  

【デプロイパイプライン】  
・マイクロサービスエコシステムは、標準化されたデプロイパイプラインを持っているか。  
・デプロイパイプラインに、完全ステージングか部分ステージングのステージングフェースが含まれているか。  
・ステージング環境は、本番サービスに対してどのようにアクセスをするか。  
・デプロイパイプラインにカナリアフェーズはあるか。  
・あらゆる障害を捕捉できるくらいの期間を使って、カナリアフェーズでデプロイを実行しているか。  
・カナリアフェーズは、本番トラフィックのランダムなサンプルを正確にホスティングしているか。  
・マイクロサービスのポートは、カナリアと本番で同じになっているか。  
・本番環境へのデプロイは一度にまとめて行なっているか、それとも漸進的に展開しているか。  
・緊急時にステージング、カナリアフェーズを省略するための手順は用意してあるか。  

【依存関係】  
・マイクロサービスの依存関係はどれか。  
・マイクロサービスのクライアントはどれか。  
・このマイクロサービスは、依存関係の障害の影響をどのようにして緩和しているのか。  
・個々のパスにバックアップ、代替サービス、フォールバック、防御的キャッシュは用意してあるか。  

【ルーティングと検出】  
・マイクロサービスの信頼性に対する健全性チェックは実行されているか。  
・健全性チェックは、マイクロサービスの健全性を正確に反映しているか。  
・健全性チェックは、通信レイヤ内で別チャネルを使って実行されているか。  
・不健全なマイクロサービスがリクエストを発行するのを防ぐサーキットブレーカーは配置されているか。  
・不健全なホストやマイクロサービスに本番トラフィックが送られるのを防ぐサーキットブレーカーは配置されているか。  

【非推奨と廃止】  
・マイクロサービスを廃止するための手続きは用意してあるか。  
・マイクロサービスのAPIエンドポイントを非推奨にするための手続きは用意してあるか。  
```  

## スケーラビリティとパフォーマンス  
<details>  
  <summary>スケーラビリティ・パフォーマンスのあるマイクロサービスの特徴</summary>  

```  
・質的、量的な成長の判断基準がわかっている。  
・ハードウェアリソースを効率よく使っている。  
・リソースの要件とボトルネックがわかっている。  
・キャパシティプランニングが自動化され、スケジュールに基づいて実行されている。  
・依存関係がマイクロサービスとともにスケーリングできる。  
・クライアントに合わせてスケーリングできる。  
・トラフィックのパターンがわかっている。  
・障害が起こった時には、トラフィックのルーティングを変えられる。  
・スケーラビリティとパフォーマンスを確保できるプログラミング言語で書かれている。  
・高いパフォーマンスが得られるように、タスクを処理している。  
・スケーラブルで高いパフォーマンスが得られるように、データを処理、格納している。  
```  
  
</details>  
  
<details>  
  <summary>要件</summary>  
  
### ・質的な成長の判断基準  
マイクロサービスに対し、いつリクエストが発行されるのか（質的な成長の判断基準）を明確にすること。  
その目的は、マイクロサービスに紐づくビジネスメトリック（ユーザ数、アイボール(携帯アプリを開く人の数)など）を把握することである。  
これによりスケーリングを計画することができる。  
質的な成長の判断基準はマイクロサービスエコシステムのスタックの下の方に進めば進むほど複雑になる。  
ビジネスメトリックとは容易に結びつかないからだ。しかしながら可能な限り明確にしておくべきである。  
  
### ・量的な成長の判断基準  
質的な成長の判断基準を、計測可能な数値に変換することによって定義される。  
例えば質的な成長の判断基準がアイボールで、1アイボールあたりマイクロサービスに2リクエスト、DBに1トランザクションが発生するなら  
量的な成長の判断基準はリクエスト数とトランザクション数で計測でき、RPSとQPSがスケーラビリティを左右する2大メトリックになる。  
  
### ・リソース配分  
CPU、メモリ、データストレージ、ネットワークは、自然界の資源（リソース）と同じ性質を持っている。  
マイクロサービスエコシステムにおけるリソース配分という組織的な課題の難しさは、  
ビジネスクリティカルなマイクロサービスに優先してリソースを与えることで緩和される。  
マイクロサービスエコシステム全体でハードウェアリソースを効果的に配分するための方法の一つは、Apache Mesosなどの  
リソース抽象化テクノロジーを使って、ホストの概念を取り除き、ハードウェアリソースの概念を導入することが挙げられる。  
  
### ・リソース要件  
個々のマイクロサービスのリソース要件を明らかにすること。  
リソースに対する要件とは、マイクロサービスが適切に動作し、効率良くタスクを処理し、垂直/水平スケーラビリティを確保するために必要な  
ハードウェアリソースのことである。  
2大ハードウェアリソースはCPUとRAMである。（マルチスレッド環境ではスレッドが第3の重要リソースとなる）  
リソース要件は、マイクロサービスの「1インスタンス」を実行するために必要なリソース（主にCPUとRAM）を定量化すれば明らかとなる。  
  
マイクロサービスのスケーリングで最も効果的で効率の良い方法は水平スケーリングであり、  
トラフィックやタスク量が増えたとき、何台のホストが必要なのか知る必要がある。  
  
そのため1インスタンスが、どれだけのトラフィックを処理できるか、CPUをどれくらい利用するか、メモリをどれくらい消費するかを数値化する。  
  
### ・リソースのボトルネック  
個々のマイクロサービスのリソースのボトルネックを明らかにすること。  
リソースのボトルネックとは、マイクロサービスのリソースの使い方の中に含まれる  
アプリケーションのスケーラビリティを制限する要素のこと。（スケーラビリティ阻害要因）  
  
基本的にスケーリングは水平に行うため、そもそも水平スケーラビリティがない（スケールアウトできない）マイクロサービスの場合は、  
スケーラビリティにボトルネックがあることになる。  
その場合は並行性とパーティション分割を指導原則として、水平方向にもスケーリングできるようにしなければならない。  
  
ボトルネックのよくある例：  
WEBサーバーを水平にスケーリングしていくとバックエンドにある単一DBへの接続数が限界に達して、これ以上スケーリングできない。  
  
ボトルネックを明らかにするためにはロードテストをしっかりと行うこと。  
  
### ・キャパシティプランニング  
ここのマイクロサービスのハードウェアに対するニーズをあらかじめ明確にし、そのニーズを予算に組み込み、必要なハードウェアを確保すること。  
そのためには質的・量的な成長の判断基準、主要なビジネスメトリック、トラフィックの予測値、既知のリソース要件、ボトルネック、トラフィック履歴を使うことができる。  
ハードウェアを入手するまでにかかる時間（リードタイム）を考慮しておくこと。それがある程度遅れることを見込むこと。  
マイクロサービスエコシステムのアプリケーションプラットフォームレイヤでキャパシティプランニングのためのセルフサービスツールを作り、実行すると良い。  
  
### ・依存関係のスケーリング  
マイクロサービスをスケーラブルに設計・構築・実装していても、依存関係がスケーラブルになっていなければ、スケーラビリティの問題に直面してしまう。  
そのため依存関係をスケーラブルにすること。  
個々のマイクロサービスが質的な成長の判断基準を使って、スケーラビリティをビジネスメトリックに結びつけるようにしておけば、  
チーム間でなかなかコミュニケーションが取れない場合でも準備は可能である。  
しかしながら本来であれば、相互の依存するチームを集めてアーキテクチャとスケーラビリティの概要を説明する会議を開き、  
サービスの全体をスケーリングするために何をしなければならないかを議論すべきである。  
  
### ・トラフィック管理  
質的・量的な成長の判断基準を使って、将来のトラフィックの増減を予測すること。  
過去のトラフィックからトラフィックパターンを理解し、サービス変更、停止、デプロイのタイミングや、監視のしきい値のチューニングなどを行うこと。  
サージ（バースト）によってサービス全体が停止してしまうことを防ぐこと。これは回復性テストスイートで対処しなければならない。  
デプロイ先のデータセンターを分離し、問題発生時にはトラフィックを分離した先にルーティングできること。  
  
### ・プログラミング言語  
並行性とパーティション分割を実現できるプログラミング言語で書かれていること。  
そういった言語でなければスケーラブルでパフォーマンスの高いサービスを作れない。  
  
### ・処理内容  
リクエストやタスクを処理するとき、処理内容に並行性が導入されていること。  
またパーティション分割されたマイクロサービスを構築できていること。  
  
### ・データストレージ  
マイクロサービスエコシステムでデータベースを構築・実行・メンテナンスする場合、3つのアプローチがある。  
（1）アプリケーションプラットフォームレイヤで管理  
（2）マイクロサービスレイヤで管理  
（3）基本はアプリケーションプラットフォームレイヤで管理し、開発チームのニーズに合わなければマイクロサービスレイヤで管理  
3つ目のアプローチがうまく機能する。  
  
データベースは一般的に、リレーショナルデータベースか、NoSQLのどちらかを選択する。  
マイクロサービスの要件によってどちらを選択すべきかを考えること。  
  
データベースはスケーリングできるように管理すること。  
  
デプロイパイプラインで部分ステージングを採用している場合、データベースがテストテナンシー機能（テストデータのマーク付け）を持ち、  
定期的にテストデータを削除できるようにしておかなければならない。  
  
</details>  

### スケーラビリティ・パフォーマンスの評価基準  
```  
【成長の判断基準】  
・このマイクロサービスの質的な成長の判断基準は何か。  
・このマイクロサービスの量的な成長の判断基準は何か。  
  
【リソースの効果的な利用】  
・マイクロサービスを実行しているのは専用のハードウェアか、それとも共有ハードウェアか。  
・リソースの抽象化、配分のためのテクノロジーを使っているか。  
  
【リソースの把握】  
・マイクロサービスのリソース要件（CPU、RAM、その他）はどうなっているか。  
・マイクロサービスの1インスタンスが処理できるトラフィックはどれくらいか。  
・マイクロサービスの1インスタンスが必要とするCPUキャパシティはどれくらいか。  
・マイクロサービスの1インスタンスが必要とするメモリはどれくらいか。  
・このマイクロサービスならではのリソース要件が他にあるか。  
・このマイクロサービスのリソースのボトルネックは何か。  
・このマイクロサービスは、水平スケーリング、垂直スケーリング、またはその両方を必要とするか。  
  
【キャパシティプランニング】  
・スケジュールに基づいてキャパシティプランニングを行なっているか。  
・新しいハードウェアのリードタイムはどれくらいか。  
・ハードウェアリクエストはどのような頻度で発生するか。  
・ハードウェアリクエストが優先的に認められるマイクロサービスはあるか。  
・キャパシティプランニングは自動化されているか、それとも手動か。  
  
【依存関係のスケーリング】  
・このマイクロサービスの依存関係は何か。  
・依存関係はスケーラブルでパフォーマンスが高いか。  
・依存関係のスケーリングは、このマイクロサービスの予想される成長についてこられるか。  
・依存関係の所有者は、このマイクロサービスの予想される成長に対して準備ができているか。  
  
【トラフィック管理】  
・マイクロサービスのトラフィックパターンはしっかりと理解できているか。  
・サービスへの変更の日程は、トラフィックパターンを中心として組み込まれているか。  
・トラフィックパターンの極端な変化（特にトラフィックのバースト）は、注意を払って適切に処理されているか。  
・障害が起こったときに、トラフィックを自動的にほかのデータセンターにルーティングできるようになっているか。  
  
【タスクの処理】  
・マイクロサービスは、スケーラブルでパフォーマンスの高いサービスを作れるプログラミング言語で書かれているか。  
・マイクロサービスのリクエストの処理方法の中に、スケーラビリティやパフォーマンスが制限される要因は含まれているか。  
・マイクロサービスのタスクの処理方法の中に、スケーラビリティやパフォーマンスが制限される要因は含まれているか。  
・マイクロサービスの開発者たちは、サービスがタスクをどのように処理しているか、その処理はどのくらい効率的か、タスクやリクエストの数が増減したときにどのように対応するか理解しているか。  
  
【スケーラブルなストレージ】  
・このマイクロサービスは、スケーラブルでパフォーマンスの高い形でデータを処理しているか。  
・マイクロサービスが格納しなければならないデータは、どのような種類のものか。  
・マイクロサービスのデータで必要とされるスキーマは、どのようなものか。  
・毎秒何トランザクションを処理しなければならないか、実際に処理されているのは何トランザクションか。  
・このサービスは、より高い読み書きパフォーマンスを必要としているか。  
・このマイクロサービスは、リードヘビー、ライトヘビー、またその両方か。  
・このマイクロサービスのデータベースは水平スケーリング、または垂直スケーリングされるか。レプリケートされたり、パーティション分割されたりしているか。  
・このマイクロサービスは、専用データベースと共有データベースのどちらを使っているか。  
・このマイクロサービスは、テストデータをどのように処理、格納しているか。  
```  
  
## 耐障害性と大惨事対応  
<details>  
  <summary>耐障害性と大惨事対応のあるマイクロサービスの特徴</summary>  

```  
・単一障害点がない  
・あらゆる障害のシナリオと起こり得る大惨事が明らかになっている。  
・障害の検出と修正が自動化されている。  
・マイクロサービス開発チーム内でも、組織全体でもインシデント、機能停止に対処するための手順が標準化されている。  
```  
    
</details>  

<details>  
  <summary>要件</summary>  
  
### ・単一障害点  
障害を起こしたらマイクロサービス全体を停止させてしまうような部品を単一障害点と呼ぶ。  
単一障害点がある場合は、その影響を緩和し、可能ならば取り除くこと。  
単一障害点は依存関係の連鎖の中で生まれることが多いので見落としに注意すること。  
  
### ・障害・大惨事  
大惨事となる障害シナリオを明らかにしておくこと。  
  
エコシステム全体、  
ハードウェアレイヤ、  
通信レイヤ、  
アプリケーションプラットフォームレイヤ、  
マイクロサービスレイヤ（外部... 依存関係起因）、  
マイクロサービスレイヤ（内部... サービス自身起因）、  
それぞれでの障害のシナリオを明らかにすること。  
  
### ・コードテスト  
lintテスト、単体テスト、結合テスト、エンドツーエンドテストを実施すること。  
また、これらはデプロイパイプラインに組み込んで自動実行すること。  
  
### ・ロードテスト  
決められた負荷のもとでマイクロサービスの動作をテストすること。  
テストする負荷を選び、その負荷のもとでマイクロサービスを実行し、マイクロサービスの動作を細かく監視すること。  
ロードテストはデプロイパイプラインの各ステージで実行し、問題が起きた場合はデプロイを中止すること。  
また、マイクロサービスの質的・量的な成長の判断基準、リソース要件、ボトルネックを明らかにするために利用できる。  
  
ロードテストはステージングだけではなく、本番環境でも実行しなければならない。  
ロードテストによりサービスが本番環境で限界に達して、システムの一部が壊れ始めたら、テストを終了するために自動化すること。  
また十分なログを取り、社内に広く知らせて、ロードテストによる問題がすぐに検出、緩和、解決されるようにすること。  
  
ロードテストを実施する場合は、アプリケーションプラットフォームとして公開とすること。  
  
### ・カオステスト  
あらゆる障害シナリオをテストすること。  
カオステストは、本番稼働しているマイクロサービスを積極的に停止させる。  
障害を起こしてもマイクロサービスが生き残れるようにするためには、絶えずあらゆる方法でマイクロサービスを障害に追い込むほかない。  
十分なログを取り、マイクロサービスをグレースフルに回復できなくなったときに問題点がわかるようにすること。  
  
カオステストを実施する場合は、アプリケーションプラットフォームとして公開とすること。  
  
### ・障害の検出と修正  
障害を検出し、修正するための戦略を準備しておくこと。目的はユーザーに対する影響を最小限にすること。  
自身のマイクロサービスで障害を検出したら、直ちに最後の安定ビルドにロールバックすること。  
依存関係で障害を検知したら、安定した代替物へフェイルオーバーすること。それができない場合はリクエストをキューイング、または保存して  
依存関係の障害が緩和されるまで保存しておくこと。  
  
障害の検出は、本番対応の「監視」の原則で実現すること。  
  
### ・マイクロサービスの分類  
マイクロサービスをビジネスにとっての重要度に基づいて分類しランク付けすること。  
  
### ・インシデント・機能停止・障害の分類  
インシデント・機能停止・障害を、深刻度とスコープに分類すること。  
深刻度... マイクロサービスの重要度が高ければ高いほど、深刻度も高くなる。  
スコープ... ローカルかグローバル。  
  
### ・インシデント対応の5つの段階  
標準化されたインシデント対応の手続きを用意すること。  
```  
1. 評価  
2. 調整  
3. 緩和  
4. 解決  
5. フォローアップ  
```  
  
</details>  

### 耐障害性と大惨事対応の評価基準  
```  
【単一障害点の除去】  
・マイクロサービスに単一障害点はあるか。  
・マイクロサービスに複数の障害点はあるか。  
・障害点は取り除けるか、それとも緩和が必要なものか。  
  
【大惨事と障害のシナリオ】  
・マイクロサービスの障害のシナリオと発生し得る大惨事は、すべて特定できているか。  
・マイクロサービスエコシステム全体を通じてよく起こる障害は何か。  
・このマイクロサービスに影響を与えるハードウェアレイヤの障害シナリオは何か。  
・このマイクロサービスに影響を与える通信、アプリケーションプラットフォームレイヤの障害シナリオは何か。  
・このマイクロサービスに影響を与える依存関係の障害シナリオは何か。  
・このマイクロサービスをダウンさせる可能性のある内部障害は何か。  
  
【回復性のテスト】  
・このマイクロサービスは適切なlintテスト、単体テスト、統合テスト、エンドツーエンドテストを持っているか。  
・このマイクロサービスは定期的にスケジューリングされたロードテストを実行しているか。  
・すべての障害のシナリオがカオステストとして実装され、テストされているか。  
  
【障害の検出と修正】  
・技術組織全体でインシデントや機能停止に対処するための標準的なプロセスが作られているか。  
・このマイクロサービスの障害や機能停止は、ビジネスにどのような影響を及ぼすか。  
・明確に定義された障害のレベルはあるか。  
・明確に定義された緩和戦略はあるか。  
・インシデントや機能停止が発生した時、チームは5段階のインシデント対応に従っているか。  
```  

## 監視  
<details>  
  <summary>適切に監視されているマイクロサービスの特徴</summary>  

```  
・ホスト、インフラストラクチャ、マイクロサービスレベルで主要メトリックが特定され、監視されている。  
・マイクロサービスの過去の状態を正確にする適切なロギングシステムがある。  
・全てのメトリックが含まれていてわかりやすいダッシュボードがある。  
・アクション可能で、しきい値に基づいて定義されているアラートシステムがある。  
・監視とインシデントや機能停止への対応を行うオンコールローテーションが実施されている。  
・インシデントや機能停止を処理するための明確に定義され、標準化されたオンコール手続きがある。  
```    
  
</details>  
  
<details>  
  <summary>要件</summary>  
  
### ・主要メトリック  
マイクロサービス のふるまいを必要十分に説明する性質を主要メトリックという。  
主要メトリックを見極め、マイクロサービスの全体的な状態、健全性がその性質のどのような変化からわかるかを掴むこと。  
主要メトリックには  
```
（1）ホスト・インフラストラクチャ  
（2）マイクロサービス   
```
の2種類がある。  
  
ホスト・インフラストラクチャのメトリックはマイクロサービスエコシステムのレイヤ1〜3のメトリックで、  
マイクロサービスのメトリックはレイヤ4のメトリックになる。  
  
チームは両方のメトリックを監視しなければならない。また、  
ホスト・インフラストラクチャのメトリックは、複数のマイクロサービスでそのハードウェアリソースを共有している場合があるため、複数のチームで共有されなければならない。  
  
主要メトリックの監視は、特定のホスト単位でも、マイクロサービスが実行されている全てのホストの合計(実際には平均)でも、主要メトリックの状態がわかるような粒度で監視する。  
例えば、ある特定のホストでマイクロサービスがどの程度CPUを使っているのかと、マイクロサービスが実行されているホスト全体でCPUをどの程度使っているのかの両方がわかるようにすること。  
リソースが抽象化されているエコシステムだとホストレベルメトリックは取りづらいが、マイクロサービス全体の主要メトリックは監視すべき。  
  
これらの主要メトリックは、デプロイパイプラインのすべてのステージでそれぞれ監視すること。  
  
```  
〜主要メトリックのまとめ〜  
【ホスト・インフラストラクチャの主要メトリック】  
・CPU  
・RAM  
・スレッド  
・ファイルディスクリプタ  
・データベース接続  
  
【マイクロサービスの主要メトリック】  
・言語固有メトリック  
・可用性  
・SLA  
・レイテンシ  
・エンドポイントの成功  
・エンドポイントのレスポンス  
・エンドポイントのレスポンス時間  
・クライアント  
・エラーと例外  
・依存関係  
```  
  
### ・ロギング  
別サービスが、最良でないマイクロサービスの別バージョンを指定して実行することがないようにしなければならない。  
そうした前提で、最新バージョンが障害を起こしてもマイクロサービスの状態がわかるようにロギングすること。  
  
ホスト・インフラストラクチャレベルの情報は、アプリケーション自体からはロギングしてはならず、  
アプリケーションプラットフォームレイヤで実行されるサービスやツールによってロギングされる。  
マイクロサービスのログにはハッシュされたIDとリクエスト、レスポンスの詳細のようなマイクロサービスレベルの主要メトリックと情報を書き込むこと。  
  
個人情報や秘密情報をロギングしないこと。一見無害なものでも個人情報につながるものは暗号化して出力すること。  
  
クライアントと依存関係の連鎖全体を通じ、エンドツーエンドでリクエストとレスポンスを追跡、ロギングすること。  
この情報にアクセスし、可視化すること。  
  
ログは膨大な量となり、格納とアクセスにコストがかかる。  
デバックログは量が多く処理コストが上がるので、本番環境で出してはならない。  
  
### ・ダッシュボード  
ダッシュボードはマイクロサービスエコシステム全体で一元管理、標準化され、簡単にアクセスできるものでなければならない。  
誰でも解釈できるようにすること。情報の詰め込みすぎでわかりづらくなったり、情報不足にならないように注意すること。  
  
ここのデプロイフェーズ（ステージング、カナリア、本番）のためのダッシュボードを用意すること。  
  
障害はダッシュボードを見なくてもわかるようにアラートを設定すること。  
  
### ・アラート  
主要メトリック（ホスト・インフラストラクチャメトリック、マイクロサービス固有のメトリック）には、様々なしきい値に基づいてアラートを設定すること。  
主要メトリックにマイクロサービスの可用性を損なう変化が見られたときにアラートが生成されるようにすること。  
また主要メトリックが見えない時にもアラートを生成すること。  
  
主要メトリックに対して、正常、警告、異常の3種類のしきい値（上限、下限）を設定すること。  
正常の範囲は問題なしのため、アラートは生成しないこと。  
警告の範囲は問題を起こしかねない状態のため、警告アラートを生成すること。  
異常の範囲は問題が起こっている状態のため、異常アラートを生成すること。  
  
アラートはアクション可能でなければならない。  
オンコール開発者が無視できてしまうアラート、すぐにアクションを起こす必要がないアラート、開発者には解決できないアラートはアラートプールから外すこと。  
  
オンコールランブックは2種類用意すること。  
```
（1）ホスト・インフラストラクチャメトリックのアラート用  
（2）マイクロサービスメトリックのアラート用  
```
メトリック一つ一つに対しての対象方法をステップバイステップで説明すること。  
  
アラート対応は自動化を目指すこと。  
そのためにオンコールランブックは役に立つ。  
  
オンコール開発者の燃え尽きを防ぐため、オンコールローテーションを設計すること。  
また一度に呼び出される開発者は2人以上、オンコールシフトは1週間未満で、次のシフトまでは1ヶ月以上離れてはいけない。  
  
依存関係が問題を起こしている場合には、依存関係のオンコール開発者を調べてすぐに連絡ができるようにしておくこと。  
  
</details>  

### 監視の評価基準  
```  
【主要メトリック】  
・このマイクロサービスの主要メトリックは何か。  
・ホスト、インフラストラクチャのメトリックは何か。  
・マイクロサービスレベルのメトリックは何か  
・マイクロサービスの主要メトリックは全て監視されているか。  
  
【ロギング】  
・このマイクロサービスがロギングしなければならない情報は何か。  
・このマイクロサービスは、すべての重要なリクエストをロギングしているか。  
・ログは、特定の時点におけるマイクロサービスの状態を正確に反映しているか。  
・このロギングソリューションはコスト効果が高く、スケーラブルか。  
  
【ダッシュボード】  
・このマイクロサービスはダッシュボードを持っているか。  
・ダッシュボードはわかりやすいか。すべての主要メトリックがダッシュボードに表示されているか。  
・ダッシュボードを見ただけでこのマイクロサービスが正しく動作しているかどうかわかるか。  
  
【アラート】  
・すべての主要メトリックに対してアラートが設定されているか。  
・すべてのアラートが適切なしきい値によって定義され、有効なシグナルを送れるようになっているか。  
・機能停止が起こる前にアラートが生成されるように、適切なしきい値が設定されているか。  
・すべてのアラートがアクション可能になっているか。  
・オンコールランブックは、すべてのアラートのトリアージ、緩和、解決の方法をステップバイステップで説明しているか。  
  
【オンコールローテーション】  
・このマイクロサービス を監視するための専用のオンコールローテーションが作られているか。  
・オンコールシフトの担当者は最低でも2人以上になっているか。  
・技術組織全体で標準化されたオンコール手続きはあるか。  
```  

## ドキュメントと組織的な理解  
<details>  
  <summary>ドキュメントと組織的な理解のあるマイクロサービスの特徴</summary>  

```  
・包括的なドキュメントがある。  
・ドキュメントが定期的に更新されている。  
・ドキュメントには、マイクロサービスの説明、アーキテクチャ図、連絡先とオンコールの情報、重要情報へのリンク、 オンボーディング/開発ガイド、サービスのリクエストフロー、エンドポイント、依存関係についての情報、オンコールランブック、FAQに対する回答が含まれている。  
・ドキュメントが開発者、チーム、組織の各レベルでよく理解されている。  
・ドキュメントが本番対応の標準に準拠しており、対応する要件を満たしている。  
・アーキテクチャが頻繁にレビュー、監査されている。  
```  
  
</details>  
  
<details>  
  <summary>要件</summary>  
  
### ・マイクロサービスのドキュメント  
マイクロサービスのドキュメントは、一元管理、共有され、簡単にアクセスできる場所に格納すること。  
社内用Webサイトが最良のメディアになることが多い。  
  
ドキュメントが技術的負債になるのを防ぐため、ドキュメントはサービスの変更とともに更新されなければならない。  
そのため開発ワークフローの中にドキュメントの更新プロセスを組み込むこと。  
  
ドキュメントは包括的で役に立つものでなければならない。以下のセクションを用意すること。  
##### 説明  
マイクロサービスの役割を理解してもらうためのセクション。  
```  
マイクロサービスがマイクロサービスエコシステムで果たす役割がわかるようにするために説明すること。  
```  
  
##### アーキテクチャ図  
サービスのアーキテクチャを詳細に知るためのセクション。  
```  
サービスのアーキテクチャを詳しく示すもので、コンポーネント、エンドポイント、リクエストフロー、クライアントと依存関係、データベースやキャッシュについての情報を含めること。  
```  
  
##### 連絡先とオンコール情報  
サービスチーム以外の人が、サービスチームにコンタクトできるようにするためのセクション。  
```  
チームの全メンバー（一般の開発者、管理職、プログラム/製品マネージャー）の名前、地位、連絡先を入れること。  
オンコールローテーションについての情報を記載すること。  
```  
  
##### リンク  
マイクロサービスについてのすべての情報を一元的にまとめるためのセクション。  
```  
リポジトリ、ダッシュボード、マイクロサービスの元々の技術仕様、最新のアーキテクチャレビュースライド、他のマイクロサービスのドキュメント、  
使用しているテクノロジー情報、その他役立つ情報へのリンクなど、開発者の役に立ちそうな情報は何でも入れておくようにすること。  
```  
  
##### オンボーディング/開発ガイド  
チームに新加入した開発者に担当するサービスに慣れてもらうとともに、マイクロサービスに機能追加してデプロイパイプラインにそれを送り込む方法を教えるためのセクション。  
```  
第1要素として、サービスの開発環境構築手順を記載すること。  
第2要素として、開発サイクルの各手順の技術的な詳細や、デプロイパイプラインへの送り込み方などを記載すること。  
これらはステップバイステップで誰でも実行できるように詳細に（コマンドや実行スクリプトなどを）記載すること。  
```  
  
##### リクエストフロー、エンドポイント、依存関係  
マイクロサービスの動作の詳細を知るためのセクション。  
```  
第1要素として、リクエストフローを記載すること。アーキテクチャ図で詳細に書ける場合は省略しても構わない。  
第2要素として、サービスのすべてのエンドポイントの名前、リクエストパラメータ、レスポンス、処理内容を箇条書きにして、他のチームの開発者が使い方を理解できるようにすること。  
第3要素として、依存関係と関連するエンドポイント、サービスが依存関係に対して行うリクエスト、依存関係のSLA、障害が起こったときの代替サービス/キャッシュ/バックアップについての情報、ドキュメントとダッシュボードへのリンクをまとめること。  
```  
  
##### オンコールランブック  
オンコール時の対応方法を知るためのセクション。  
```  
すべてのアラートについて、名前、アラートの説明、アラートのトリアージ、緩和、解決方法のステップバイステップガイドであること。  
新しいエラーをトラブルシューティング、デバッグするための一般的な説明と詳細説明の両方を含めること。  
```  
  
##### FAQ  
サービスについてよく質問されることに対する回答をまとめたセクション。  
```  
オンコール担当者やチーム全体が頻繁に質問される事項について記載すること。  
チーム外からの質問だけでなく、チームメンバーからのよくある質問も記載すること。  
```  
  
### ・マイクロサービスについての組織的な理解  
マイクロサービスの理解のレベルには3種類ある。  
```  
・開発者レベルの理解  
自分が担当するマイクロサービスについて質問に答えられる状態。  
・チームレベルの理解  
チームが担当するマイクロサービスが本番対応に関してどのような位置にあり、何を実現しなければならないかわかっている状態。  
・組織レベルの理解  
組織全体が本番対応に必要な原則をわかっていて、全てのサービスを本番対応にするためのプロセスを全社的に組み込んでいる状態。  
```  
  
全社的なプロセスとしてアーキテクチャレビューを行うこと。  
  
全てのサービスに対して本番対応の監査を行い、本番対応の度合いを定量化すること。  
  
監査を行ったら本番対応のためのロードマップを作成すること。  
  
本番対応チェック（アーキテクチャレビュー、監査、ロードマップ作成）を自動化すること。  
  
</details>  
  
### 本番対応の評価基準  
```  
【マイクロサービスのドキュメント】  
・マイクロサービスのドキュメントは一元管理、共有され、簡単にアクセスできる場所に格納されているか。  
・ドキュメントは簡単に検索できるか。  
・マイクロサービスを大きく変更したときには、マイクロサービスのドキュメントも更新されているか。  
・マイクロサービスのドキュメントにマイクロサービスの説明が含まれているか。  
・マイクロサービスのドキュメントにアーキテクチャ図が含まれているか。  
・マイクロサービスのドキュメントに連絡先とオンコール情報が含まれているか。  
・マイクロサービスのドキュメントに重要な情報へのリンクが含まれているか。  
・マイクロサービスのドキュメントにオンボーディング/開発ガイドが含まれているか。  
・マイクロサービスのドキュメントにリクエストフロー、エンドポイント、依存関係についてに情報が含まれているか。  
・マイクロサービスのドキュメントにオンコールランブックが含まれているか。  
・マイクロサービスのドキュメントにFAQセクションが含まれているか。  
  
【マイクロサービスについての組織的な理解】  
・チームのすべての開発者がマイクロサービスの本番対応についての質問に答えられるか。  
・すべてのマイクロサービスが満たさなければならない原則や標準はまとめられているか。  
・新規開発されるマイクロサービスが通過しなければならない技術仕様プロセスはあるか。  
・既存のマイクロサービスのレビュー、監査は頻繁に行われているか。  
・すべてのマイクロサービスチームでアーキテクチャレビューが行われているか。  
・本番対応の監査プロセスは用意されているか。  
・マイクロサービスを本番対応の状態に引き上げるためのロードマップが使われているか。  
・会社のOKRは本番対応の標準に基づいて設定されているか。  
・本番対応のチェックプロセスは自動化されているか。  
```  
