# NOSQL  
NOSQLとは、Not Only SQLの略で「SQLだけでは十分でない」という意味である。  
これは"SQL(RDB)ではビッグデータ対応には"十分でない、という意味である。  
  
# ビッグデータ対応  
ビッグデータとはサイズの小さなデータが膨大に集まり、大きなデータの塊になったものを指す。  
単に大きなファイルは「ラージオブジェクト」と呼ばれる。  
  
「ビッグデータ対応」とは3Vに対応するということである。  
```  
3V  
・膨大な量 = Volume  
・速さ = Velocity  
・多様性 = Variety  
```  
  
### 膨大な量 = Volume  
ビッグデータを格納・処理することはハードウェアの性能向上（ハードディスクを大きく速いものにする）だけでは到底追いつけない。  
安価ながらそれなりの性能を持ったハードウェアを複数ならべ、あたかも一つの最高性能の装置のように扱う必要がある。  
  
### 速さ = Velocity  
ビッグデータを高速に処理することはハードウェアの性能向上だけでは到底追いつけない。  
こちらも分散して処理する仕組みが必要である。  
  
### 多様性 = Variety  
ビッグデータはデータの形が多種多様に変化していくもので、複雑なデータ構造と、複雑な相互関係を持つ。  
これらに対応できる仕組みが求められる。  
  
RDBは単一ハードウェアで稼働する場合は最適だが、データを分散させるには不向きだ。  
また多種多様なデータにおいてRDBでいう構造化は不可能である。  
結果、NOSQLが求められた。  
  
# 分散システム  
分散システムとは「クラスタ」構成のシステムを指す。  
クラスタとは、安価ながらそれなりの性能を持ったハードウェアを複数ならべ、あたかも一つの最高性能の装置のように扱う構成をいう。  
  
つまり分散システムとは何らかの性能を最高レベルに達させたものであり、それがどのような性能なのかはコンテキストによって異なる。  
  
NOSQLの分散システムで実現した最高レベルの性能で特徴的なのは、「膨大なデータの取り扱い」「信頼性」の二つである。  
  
### 膨大なデータの格納・処理  
シャードのクラスタを構成（シャーディング）することで実現  
  
利用される概念・技術  
```  
・拡張性を考慮したシャーディングアルゴリズム  
・シャーディングキー選定  
```  
  
### 信頼性  
レプリカのクラスタを構成（レプリケーション）することで実現  
  
利用される概念・技術  
```  
・CAP定理  
・整合性の調整  
・CAS操作  
・マスタ / P2P アーキテクチャ  
・マスタの特性・選出パターン（マスタ型アーキテクチャの場合）  
```    
  
# NOSQLのデータモデル  
### SQLのデータモデル  
表の形でデータ構造を設計し、正規化でデータの冗長性と不整合を排除している。  
これにより個々のデータは定型化され、相互の関係性が明確に定義される。  
データの発生よりも先にデータ構造をテーブルの形に固定しておくことで、その関係性に揺らぎが生じないようになっている。  
  
### キー・バリュー（KVS）型NOSQLのデータモデル  
テーブルや関係性を定義せずに、「キー」と「バリュー」の組み合わせからなるシンプルなデータモデル。  
キーによりバリューを一意に識別する。  
  
データが増えるに従って縦方向（行）に伸びていく。  
  
特徴  
```  
・データモデルがシンプル  
SQLのようなスキーマがなく、多くはキーはstring, バリューはBLOB（Binary Large OBject : ブロブ）でもつ。  
  
・スケールアウトに最適  
データ間の関係性がないため整合性を保つための排他ロックが不要なため、複数サーバーでデータをシャーディングすることが容易である。  
  
・レプリケーションが可能  
シャーディングだけではなくレプリケーションを考慮したNOSQL製品もある。  
```  
  
### カラム指向型NOSQLのデータモデル  
キー・バリュー型を少し高度にしたデータモデルで、1つのキーが1つのバリューと対になるのではなく、  
複数のキー・バリューを1キー（行キー）でグループ化するデータモデル。個々のキー・バリューをカラムと呼んでいる。  
グループ化されたカラム群と行キーを合わせてカラムファミリーと呼ぶ。  
  
テーブルではないのでキー毎のカラム数は固定されておらず、動的に追加できる。  
また全てのカラムにバリューが挿入されていないことも許容される。  
  
データが増えるに従って縦方向（行）と横方向（列）に伸びていく。  
  
特徴  
```  
カラムファミリー名と行キーは予め定義しておく必要があるが、その中のカラム（キー・バリュー）は動的に増やしていくことができる。（横方向に伸びていく）  
例えばカラム名（つまりキー）をタイムスタンプにして追加していくなど。  
当然、行キーが追加されていくこともある。（縦方向に伸びていく）  
  
キー・バリューと同様にスケールアウトに最適である。  
```  
  
### ドキュメント指向型NOSQLのデータモデル  
JSONやXMLなどの書式で記述されたドキュメントの形でデータを管理するデータモデル。  
  
特徴  
```  
内容をクエリできる  
```  
  
### グラフ型NOSQLのデータモデル  
データとデータのつながりを管理できるデータモデル。  
  
特徴  
```  
ノード・リレーションシップ・プロパティを使って経路を書くこと（グラフ化）を機能として提供している  
```  
  
# NOSQLのアーキテクチャ  
NOSQLのアーキテクチャは大きく、GoogleのBigtable系と、AmazonのDynamo系の2種に分類される。  
  
### Google Bigtable系  
GoogleのBigtable系は「マスタ型」と呼ばれ、一つのマスタノードが、配下にある多数ノードを管理する構成をとる。  
マスタノードがダウンする障害にはマスタ選出パターンで備える。  
  
CP（CAP定理）システムであり、必ず整合性が保たれるが可用性は低い。（強い整合性）  
書き込まれたデータを同期的にノード間で複製している。  
  
### Amazon Dynamo系  
AmazonのDynamo系は「P2P」と呼ばれ、マスタノードに該当するものは存在せず、全てのノードが対等にお互いを管理し合う構成をとる。  
こちらは単一障害点がないというメリットがある。  
  
AP（CAP定理）システムであり、高い可用性を持つが結果整合性である。（弱い整合性）  
各ノードが更新を受け付け、ノード間で差異があった場合にDBMS側で修復する。  
  
### CAP定理  
分散システムにおける定理。  
```  
CAP定理の文脈におけるDBMSの分散システムは、レプリカのクラスタを意味する。  
マイクロサービスの分散システムとは、各サービスが互いに連携して1業務を実現していることを意味する。  
```  
今回はDBMSの分散システムの話。  
  
ノードA・Bがあったとき、  
```  
・クライアント1がAに書き込み→AはBに連携→Bも書き込み→Aがクライアント1にレスポンス返す  
・クライアント2がBにクライアント1が更新したデータの参照を要求する→Bがクライアントに最新データを渡す  
```  
という流れを守ることにより整合性を保ち、クライアント1,2の可用性を維持している。(これはABが分断されることを考慮していない）  
  
もしネットワーク障害によりAとBの間が分断された場合、この構成は破綻するためABを停止するしかない。  
つまり分断耐性（P）が無い。(RDBはこのCAシステム)  
  
ABが分断された時にサービスを停止しない（分断耐性を持たせる）にはどうすればよいか。このときがCPとAPへの分かれ道となる。  
**・整合性を担保するCPシステムにする**  
```  
AかBどちらかを停止する。  
例えばBを停止してクライアント2の参照・書き込みを失敗させることで、Aのクライアント1は常に整合性の取れた最新のデータで処理を続行できる。  
しかし当然クライアント2の可用性は失う。  
```  
**・可用性を担保するAPシステムにする**  
```  
AとBを稼働させ続ける。  
これによりクライアント1・2の可用性を維持したままサービスを続行できる。  
しかしクライアント1は2が書き込んだデータを参照できないし、その逆も然りなのでデータの整合性は失われる。  
```  
  
### 整合性の調整  
CAP定理はあくまで理論的に割り切ったものであり、実際には整合性は調整することができる。  
それにはQuorum（クォーラム）という基本概念を用いる。  
```  
Quorum : R + W > N の場合には整合性を保証できる。  
  
R（読み込み数）とW（書き込み数）の合計がN（ノード数）より大きい場合、必ず最新のデータを見つけることができるということである。  
例えば  
3ノード(ABC)あったとき、書き込みを2ノード(AB)に行い、読み込みを2ノード(BC)に行うと、必ず書き込まれたデータがあるノード(B)にアクセスすることができる。  
```  
  
Quorumの整合性調整により、サーバーダウンやネットワーク障害で1ノードと通信できなくなったときもサービスを稼働させ続け（分断耐性を実現し）、  
クライアントは2ノードにアクセスできるので可用性が保たれ、かつ整合性までも確保している。（この構成では2ノードダウンには耐えられないが）  
  
当然、書き込みや読み込みの処理が大きくなるため、性能とのトレードオフになる。  
  
### データのバージョン管理  
複数クライアントから同時に書き込みがありその内容が衝突する場合、どうやってデータのバージョンを管理し、最新バージョンに落ち着かせるのか。  
方法としては「タイムスタンプ」と「ベクタークロック」がある。  
  
##### タイムスタンプ  
その名の通り時間的な後先に従ってバージョン管理し、「新しいものが勝つ」というシンプルなルールを適用する。  
しかし完全に同時に書き込まれた場合や、ノード間でタイムスタンプの同期が難しい場合は「ベクタークロック」を用いる。  
  
##### ベクタークロック  
省略  
  
### CAS操作  
強い整合性を保証するNOSQLの中にはCAS（Check And Swap）という操作をサポートするものもある。  
```  
CAS操作 :   
ある値を更新する際に、その値を自分のプロセスが読み込んだ後に、別のプロセスによって更新されていないことを確認して  
それが確認できた場合にのみ自身の更新を適用するというオペレーション。  
```  
  
# Hadoop  
Hadoopとは複数のソフトウェアを包含するフレームワークであり、2つの主要プロダクトで構成される。  
HadoopはNOSQLではない。  
  
**・hadoop HDFS**  
マスタ型の分散ファイルシステム。  
NOSQLとの違いは一度のデータ転送量を重要視し、レスポンスタイムが低くても問題ない設計になっていること。  
  
**・hadoop Map Reduce**  
バッチ処理システム。  
  
# NOSQL製品の分類  
### 分類  
横軸：マスタ型, P2P型, イネーブラ型(オンメモリ), イネーブラ型(オンディスク)  
縦軸：  
キー・バリューストア(KVS)  
カラム指向型データストア  
グラフ型データストア  
ドキュメント指向型データストア  
  
イネーブラ型とは、他のデータベースと組み合わせたときに特段の利用効果を得られるものを指す。  
イネーブラの意味は成功要因。  
もちろん単体でも利用できる。  
  
# キー・バリューストア(KVS)  
### マスタ型  
**・Hibari**  
```  
・チェインレプリケーションによる強い整合性  
```  
  
### P2P型  
**・Dynamo**  
```  
・結果整合性  
・バージョン管理をクライアント側に実装  
・DynamoはAmazon社外で手に入れることはできないがAWS上でDynamoDBとして似た機能を提供  
```  
**・Voldemort**  
**・Riak**  
  
### イネーブラ型（オンメモリ）  
**・Memcached**  
```  
・あるサーバーがDBからキャッシュしたデータを、複数サーバーからアクセスできるようにする。  
・ノード間の複製は行なっていない。  
```  
**・Redis**  
```  
・様々なデータ構造を持てる（データストラクチャ・ストアとも呼ばれる）  
・複製のためのマスタ・スレーブ型  
・Redis では公式から Replication, Sentinel, Cluster の3つの冗長構成が選べる https://hobik-site.blogspot.com/2018/09/redisreplicationsentinelcluster.html  
・結果整合性  
・定期的にメモリからディスクに書き出せる  
```  
**・Scalaris**  
```  
・Quorumにより強い結果整合性を保証  
```  
  
### イネーブラ型（オンディスク）  
  
# カラム指向型データストア  
### マスタ型  
**・HBase**  
  
### P2P型  
**・Cassandra**  
```  
・Dynamoの完全な分散設計とBigtableのカラムファミリ型データモデルが一緒になったもの  
・整合性の調整が可能  
```  
  
# グラフ型データストア  
### マスタ型  
### P2P型  
  
# ドキュメント指向型データストア  
### マスタ型  
**・CouchDB**  
**・MongoDB**  
```  
・書き込みはマスタ、読み出しはスレーブから行う  
```  
  
# NOSQLの選択基準  
## 技術特性  
用途に応じて求められる技術特性を、整合性・可用性・拡張性・柔軟性・機能性・永続性に分けて選定する。  
  
### 整合性を重視する場合  
### 可用性を重視する場合  
### 拡張性を重視する場合  
### 柔軟性を重視する場合  
### 機能性を重視する場合  
### 永続性を重視する場合  
  
## 性能面  
書き込み性能、読み出し性能、拡張性、弾力性の観点からその性能で選定する。  
  
## ビジネス適用  
商用サポートや商用パッケージ、OSSであればコミュニティの充実度から選定する。  

# メモ
```
【キーワード】
データモデル
アーキテクチャ

シャーディング
レプリケーション
整合性(Consistency)
可用性(Availability)
分断耐性(Patition Tolerance)

Quorum
CAS操作

パフォーマンス

フェイルオーバー

マルチリージョン(データセンタ)

運用

「マスタ型」
「P2P」

結果整合性

データセンター間の書き込み・読み込みによる遅延

強い整合性
弱い整合性(結果整合性)

読み込みリクエスト
書き込みリクエスト

調整可能な整合性
直列化可能な整合性

「レプリケーションファクタ」と「一貫性レベル(Consistency Level)」
レプリケーションファクタ:クラスタ内でデータの更新を伝搬させたい(レプリケーションさせたい)ノード数
一貫性レベル:書き込みのときは、いくつのレプリカ(ノード)に書き込みを行うのか、読み込みの場合は、いくつのレプリカからデータを返答させるのか

ACID特性→トランザクションを実現するための4つの条件
https://www.atmarkit.co.jp/ait/articles/1703/01/news194.html
https://qiita.com/suziq99999/items/2e7037042b31a77b19c8
BASE→
https://www.infoq.com/jp/articles/cap-twelve-years-later-how-the-rules-have-changed/
https://techblog.yahoo.co.jp/architecture/2015-04-ditributed-consistency/
CAS→強い整合性がないと不可能。←なぜ？

整合性とかトランザクションとかの定義が適当になってるからACIDも理解しづらい。
https://www.atmarkit.co.jp/ait/articles/1801/31/news011_3.html
ACIDは特性
BASEも特性
トランザクションとは一連の処理。
ACIDに準拠したシステムでは様々な業務においてトランザクション処理に一貫性が生まれる。
BASEは準拠したシステムでは信頼性は低くなる。

同時実行制御(排他制御)

ACIDはトランザクション処理システムのDBならば備えておくべき特性である。
A=原子性：アトミック性。トランザクションはすべて実行できるか、まったく実行できないかのどちらか。アトミック(原子）とは処理がそれ以上分解できないということ。
C=一貫性：トランザクション中にDBのルール（一意制約、負の数値が入らない等）が守られること。
I=独立性：トランザクションを複数実行しても単独実行の場合と同じ結果になること。他のトランザクションはその途中の状態を観測できない。
D=耐久性：トランザクションの結果は障害が発生しても失われない。
RDBではACID特性を備えている。独立性に関しては厳密に行うには全トランザクションを直列で処理する他ないため、
性能を考慮し分離レベルとして緩める設定を提供している。
NOSQLではトランザクション処理ではなくビッグデータ対応を前提にしているため、ACIDの全てを備えているものは少ない。
NOSQLでもトランザクション処理を行うシナリオはあり得るため、製品のACID特性を吟味する必要がある。
ちなみにCAP定理におけるC=一貫性は、共通のデータを扱うネットワークで繋がったシステムが、単一の最新データを持っていること
という意味でACID特性のCとは別なので注意。

CAP定理は、共通のデータを扱うネットワークで繋がったシステムが3つの望ましい性質のうち、2つしか満たせないことを示す。
・一貫性(C)、つまり単一の最新データを持っていること
・そのデータの更新に対する高可用性(A)
・そして、ネットワーク分割に対する耐性(P)
C:一貫性があるということは、全ノードが最新データを持てない場合は更新処理失敗にするということ。強い整合性ともいう。
A:データ更新に対する可用性が高いということは、更新処理失敗率が低いということ。
P:ネットワーク分割に対する耐性とは、システムが障害でグループに分かれてしまっても処理を続けられること。（滅多にない）
実際にはこれら3つの性質はレベルを調整することで全て実現できる。
参考：
https://www.infoq.com/jp/articles/cap-twelve-years-later-how-the-rules-have-changed/

CAS操作は、元の値に依存した更新処理のこと。

フェイルオーバー
ホットスタンバイ
コールドスタンバイ

データの消失について

強い整合性はデータが複製ノード間で常に同じということ。これは弱い整合性(結果整合性)＋Quorumでも実現できる。

【Cassandra】
Commit Log
Memtable
SSTable

レプリケーション係数は最低1。1の場合は各行は一つしかない。

SimpleStrategy
NetworkTopologyStrategy

リクエストを受けたときに書き込む数の話と、
全てのレプリカに配置するタイミングの話がごっちゃになっている。
例えばレプリケーション数3で、書き込みの整合性レベルがONEのとき、レプリカ1に書き込みできればOKレスポンス。
残りのレプリカにはいつコピーされる？バックグラウンド？リードリペア？
答え：読み込みも書き込みも、コーディネーターにより無条件にすべてのレプリカノードに対して実行される。
コーディネーターがクライアントに対し成功レスポンスを返すかどうかを整合性レベルで決める。
その後レプリカ間に差異があればバックグランドで修復が行われる。
参考
https://docs.datastax.com/ja/dse/5.1/dse-arch/datastax_enterprise/dbInternals/dbIntClientRequestsReadExp.html

レプリカの配置場所は基本、クラスタのリング上に分散するようになっている。そのうえで
RackUnawareStrategy：データセンターを気にせず分散する。
RackAwareStrategy：異なるデータセンターに分散する。
で決める。
参考
https://cwiki.apache.org/confluence/display/CASSANDRA2/Operations+JP

あるタイミングでサーバーの電源が切れたとき、データは消失しない。

スニッチとはDCのネットワーク・ラック情報。

マルチDCでクライアントが接続するデータセンターはどう決まる？
←クライアントのロードバランスポリシー。フェイルオーバーの設定も含む。
https://academy.datastax.com/planet-cassandra/data-replication-in-nosql-databases-explained-jp
https://docs.datastax.com/ja/dse/6.7/dse-dev/datastax_enterprise/appDevGuide/driversLoadBalancing.html
複数データセンターのユースケースは主に3つ
・ライブバックアップ/リカバリ
・作業負荷の分離
・地理的な分散配置

DC1が死んで、ライブバックアップとしてDC2に切り替えるときに整合性レベルを変えればよい。←これがリトライポリシーのこと？可能なことは確か。
DC1使ってるときは書き込みEACH_QUORUM、読み込みLOCAL_QUORUMで、
切り替え時に書き込みLOCAL_QUORUM、読み込みLOCAL_QUORUMで運用すれば、まったく整合性が乱れない。
疑問1:
DC1のとき書き込みLOCAL_QUORUM、読み込みLOCAL_QUORUMだと低レイテンシで良いのだが、
DC2に切り替えたときDC1で書き込み成功したデータがDC2にコピー(書き込み)されるより前にDC2から読み込まれると整合性がなくなる。
これはどれくらいあり得るのだろうか？また無くすことはできないのだろうか？
←パターンとしては2つ。
1.DC2への書き込み処理が完了する前にDC2への読み込み処理が走ってしまう。←これはトランザクションでいけないか？もしくはアプリ側の制御で。
2.DC2のノード障害で書き込み失敗していて、復旧後、データリペアされる前に読み込みされる。←ヒンテッドハンドオフの制御等でいけないか。
どちらも低確率だが、発生を0%にする方法がないか
疑問2:
障害発生したDC1のライブリカバリはどのように行われる？
←DC追加と同じ考え
https://docs.datastax.com/ja/dse/5.1/dse-admin/datastax_enterprise/operations/opsAddDCToCluster.html
疑問3:
3つのマイクロサービスが一つのCassandra使ってたとして、1つのマイクロサービスで書き込み失敗してDC2に切り替えたとすると
もう2つのマイクロサービスがDC1使い続けたときどうなる？
←マイクロサービスがそれぞれ独立したデータを扱っていれば問題ない。

日本語のwiki
https://cwiki.apache.org/confluence/display/CASSANDRA2/Operations+JP

ロードバランスポリシーについて
ロードバランスポリシーはクエリープランを返却する。
クエリープランはノードのリストになっている。
ドライバーはクエリーが実行されるたびに、ロードバランスポリシーでどのホストがクエリーを受信する資格があるかを決定するクエリー・プランを返す。
ドライバーは、リストの最初のホストを使用して要求を実行し、後続のホストはリトライおよび推測的実行のために残しておく。
https://docs.datastax.com/en/drivers/java/3.6/com/datastax/driver/core/policies/LoadBalancingPolicy.html
↑のJavaのdriverのJavaDocを見てみると、いくつかのLoadBalancingPolicyインタフェイスの実装と、
Chainインタフェイス(ChainOfResponsibilityかDecorator)があるので組み合わせて使うっぽい。
トークン認識ポリシー... クエリのプライマリキーからデータを所有するレプリカを取得しリストの先頭に設定する。サーバー側の追加のネットワーク接続を回避する。
データセンター認識ポリシー... ドライバーに設定しているローカルデータセンターのノードがリスト上で優先されるようにするポリシー。

ドライバーはクラスタの1ノードにでもアクセスできればゴシッププロトコルを利用して全ノードの情報が得られる。
https://docs.datastax.com/ja/dse/6.7/dse-dev/datastax_enterprise/appDevGuide/driversReconnectionPolicies.html

ドライバに静的に設定するノードリストは？
もしIP指定なら、そのノードがダウンした後にアプリの再起動等で接続プールが破棄されたらCassandraに接続できないのでは？
←ありうるかも。

DC2をクエリープランに含めないポリシーはある？
←

DC1からDC2への切り替え方法
自動：
手動：

【Redis】
トランザクション中のすべてのコマンドはシリアライズ化され、順番に実行されます。
他のクライアントからのリクエストがRedisトランザクションの実行中に行われることは決してありません。
http://redis.shibu.jp/commandreference/alldata.html
つまりトランザクションに独立性はある。理由はシングルスレッドだから。←クラスタ構成で更新ノード(マスタ)が複数あると無理では？
←更新データがシャーディングされるので大丈夫。
アトミック性はない。理由はトランザクション中に障害が発生すると、途中まで実行されてしまうから。

あるタイミングでサーバーの電源が切れたとき、データは消失する。

複数データセンターの構成
https://qiita.com/MahoTakara/items/dece9d0d4fd4094a3bc4

評価軸
[製品]
    [特性(なにができるか)]
        ★整合性（必ず最新データを読み込める）
        ★可用性（障害発生時に書き込める、書き込み成功したデータを読み込める）
        拡張性（システムを止めることなくスケールアウトできる）
        柔軟性（データモデルを柔軟に設計できる）
        ★機能性（ACID準拠トランザクションやインデックスがある）
        ★永続性（障害発生時に書き込み成功済みデータの消失を防げる）
    [性能(どのくらいできるか)]
        書き込み・読み出し性能(単一・マルチデータセンター構成の場合,レイテンシ)
        拡張・弾力（ノード数の限界、ノード追加時の性能変化）
[人]
    [開発運用]
        情報量（日本語記事、他社事例）
        管理ツール
    [ビジネス]
        製品サポート
        費用
```
