# ・基本アーキテクチャ  
OSがディスクに対して可能な最少アクセス単位はセレクタ  
一度のアクセスで１セレクタしか取得出来ないと不便なので、幾つかのセレクタをまとめたブロックという単位でアクセスする  
  
RDBMSはテーブルやインデックス等のオブジェクト毎に、ディスクに一定の領域（数ブロック分）を確保する。この領域をエクステントという。  
エクステント内にはページという論理区画が複数用意される。ページは数ブロック分のサイズである。  
RDBMSがOSにディスクアクセスを依頼するときは、ページ単位のやりとりとなる。  
  
テーブルエクステントのページには、ページのメタ情報、[rowId => レコードデータのポインタ, ...]配列(レコードディレクトリ)、空き領域、レコードデータの順で格納されている。  
空きがあるページをフリーリストとしてRDBMSが管理しており、適当なページの空きにレコードデータが追加されていくため、レコード順序は守られていない。  
あるページのレコードデータを取得するときは、レコードディレクトリの配列をなめていきレコードデータのポインタから取得する  
  
インデックスエクステントのページには、ページのメタ情報、B木構造の[キー => レコードデータのポインタ, ...]配列が格納される  
この配列はキーでソートされており、ソートアルゴリズムは？？？  
探索アルゴリズムはニ分探索  
詳細⇒http://itpro.nikkeibp.co.jp/article/COLUMN/20060113/227231/  
  
インデックスページは4種類  
プライマリーキーページ...テーブルに一つだけ＋キーに重複が無い＋NULLがない  
ユニークキーページ...キーに重複が無い  
マルチプルキーページ...特に制約はない  
複合キーページ...二つのキーの組み合わせでユニークとなる[第1キー：第2キー => レコードポインタ, ...]となり、第1キーでソートされる。  
第1キーだけWHERE句で指定するとソートされているのでインデックスを利用できるが、第2キーは第1キーが重複している分だけソートされているので、インデックスを使用できない  
詳細⇒http://use-the-index-luke.com/ja/sql/where-clause/the-equals-operator/concatenated-keys  
DESCで確認できる  
  
# ・SQL    
RDBMSはSQLを実行するまでに、三つのプログラムが連携する  
【構文解析プログラム】  
【プランナ（オプティマイザ）プログラム】  
【実行プログラム】  
  
【構文解析プログラム】  
SQLがRDBMSに渡されると、構文解析プログラムがそれを受け取る  
これは、SQLを分解し、構文ツリーを作成する  
データベースの情報（カタログという）を確認し、整合性が確保出来たらプランナ(オプティマイザ)プログラムに構文ツリーを渡す。  
  
【プランナ（オプティマイザ）プログラム】  
構文ツリーから、論理プランを作成する  
論理プランとは、最終的にSQLに対する回答を得ることができる、テーブルに対する関係代数演算（選択、射影、結合など）の一連の流れのこと。  
論理プランは、関係代数の規則や性質を利用して、出来るだけ結合の回数が少ないプランが選ばれる。  
論理プラン中の一つの関係代数演算に対応する実装モジュールは複数用意されており、一つの論理プランの実行方法（物理プラン）は複数ある。  
複数の物理プランから、カタログを利用して、もっとも処理時間が短いものを選択し、その物理プランを実行プログラムに渡す。（コストベースオプティマイザの場合）  
この作業を「最適化」という。  
※ルールベースオプティマイザではカタログは使用せず、アクセスパス（物理プラン）の順位表から選択される  
  
【実行プログラム】  
物理プランを実行する。  
  
RDBMSがテーブルを「結合」（関係代数演算）する際に利用するアルゴリズムには，  
「ネスト・ループ結合」Nested Loop 結合  
「マージ結合」  
「ハッシュ結合」  
の三つがあげらる。  
MySQL には 「結合」に対応するモジュールは一つしかなく、そのモジュールはネスト・ループ結合を使っている。  
  
ネストループ結合は最初にアクセスする表(外部表、駆動表とも呼ばれる)をフェッチし、  
そのフェッチしたデータと結合可能なデータを内部表から(インデックスがあれば利用して)検索する処理をループして結合する。  
結合の詳細⇒http://www.atmarkit.co.jp/ait/articles/0408/25/news101.html  
  
# ・インデックス
【参考】 http://use-the-index-luke.com/ja  
インデックスによる検索は、(1) ツリーを走査し、(2) リーフノードチェーンをたどり、(3) テーブルからデータを読み出す、という3ステップで行われる。  
Oracleデータベースではインデックスを使った基本的な検索の方法を表す、以下のような3つのはっきりした区分がある。  
INDEX UNIQUE SCAN  
木の走査しか行わない。Oracleデータベースでは、ユニーク制約により、検索条件が 必ず1つしかないことが確実な場合に、この方法を使用。  
INDEX RANGE SCAN  
一致する全ての エントリを探すために、木の走査に加えて リーフノードチェーンをたどった検索も行う。検索条件に対して複数のエントリが存在する可能性がある場合の代替策。  
TABLE ACCESS BY INDEX ROWID  
テーブルから行を読み出す。この操作は、直前に行われたインデックス スキャンの結果から、一致するレコードを読み出すために行われる。  
  
実際の処理を考えると、  
１．ユニークなインデックスを利用して、インデックスカラムのみ読みだす... INDEX UNIQUE SCAN  
２．ユニークでないインデックスを利用して、インデックスカラムのみ読みだす... INDEX RANGE SCAN  
３．ユニークなインデックスを利用して、複数カラムを読みだす... INDEX UNIQUE SCAN　⇒　TABLE ACCESS BY INDEX ROWID  
４．ユニークでないインデックスを利用して、複数カラムを読みだす... INDEX RANGE SCAN　⇒　TABLE ACCESS BY INDEX ROWID  
となる  
  
インデックスを遅くする完璧な組み合わせは、広い範囲のインデックス探索と、たくさんの行を1行ずつ読み出す処理。（４．で対象が大量な場合）  
この場合は、インデックスがあろうと、フルスキャンモジュールを使用した物理プランを選択してほしい。  
そうさせるためには、カタログを最新にしておくべき。  

### 関数インデックス
製品によってはサポートされていないが、関数インデックスというものがある。
```
CREATE INDEX emp_up_name 
    ON employees (UPPER(last_name))
```
のようなクエリで作成できる。これはlast_nameにインデックスが作成されていても、WHERE UPPER(last_name) = XXXX;で検索した時に
インデックスを利用してくれるようにするためである。  
※last_nameとUPPER(last_name)は別物扱い。  

関数インデックスを作成するためには、その関数が引数に対して固定の値を返却するもの(確定的)でなければいけない。  
例えば、引数に日付を与えると年齢を返す関数は、時が経つにつれて返却値が変わっていくためインデックスは作成できない。  
関数が確定的であるためには、確定的であると宣言したものである必要がある。 これにはDETERMINISTIC (Oracle)あるいはIMMUTABLE (PostgreSQL)を使用する。


### パラメータ化クエリ

通常のSQLは最適化の際、SQL文にあるカラムの値がどの程度の頻度で現れるかを判断するために、ヒストグラムを使う。  

「バインドパラメータ」を利用したSQLは、どのような最適化が行われるのか。 
与えられた値がどの程度の 頻度で出現するか明確な情報は持っていない。全て同じように分布していて、同じ行数の見積もり、同じコスト値が得られると推測するだけ。そのため、いつも同じ実行計画を使うことになる。  
※LIKE検索でバインドパラメータがある場合、ワイルドカードを使用した検索は行われないと判定するデータベースがほとんど。PostgreSQLは例外で全文検索を選択する

最適化のオーバーヘッドをなくすためバインドパラメータを利用するか、正しい最適化を求めてバインドパラメータを利用しないかはトレードオフ。

・実行計画のキャッシュ
SQLServerやOracleのように、実行計画をキャッシュするデータベースでは、 複数回実行される同じ文に対して同じ実行計画を再利用することができる。  
これにより、実行計画を作成し直すコストを節約できるが SQL文は完全に同じでなければならない。  
そのために「バインドパラメータ」を利用すると、同じSQL文として認識させ、実行計画キャッシュを使うことができる。
  
  
### 範囲検索
誤解を恐れずに言えば、インデックスはまず等価性を確認するためにあり、それから範囲を調べるために使われる。  
複合インデックスの場合は特に顕著にその性質が現れる。  
【SQLで where 範囲 AND 等号; 検索をした場合】    
・複合インデックスの左側が範囲検索、右側が等号検索に使われた場合  
左側が一意に決まらないので、検索範囲の最初の値があるリーフノードからINDEX RANGE SCANされる。※アクセス述語＋フィルタ述語になる。    
・複合インデックスの左側が等号検索、右側が範囲検索に使われた場合  
左側が一意に決まるのでリーフノードが一意に決まる。※全ての条件をアクセス述語として使う。  
【参考】http://use-the-index-luke.com/ja/sql/where-clause/searching-for-ranges/greater-less-between-tuning-sql-access-filter-predicates  
　　
*アクセス述語は、インデックスをスキャンする範囲を定義する。*  　
*フィルタ述語は、スキャン後のリーフノードデータやレコードデータ群の走査時にのみ適用される。*  
※もちろん、リーフノードデータに対してフィルタできる方が、レコードデータ取得の必要が無いので効率が良い。これを利用して、
```
SELECT first_name, last_name, subsidiary_id, phone_number
  FROM employees
 WHERE subsidiary_id = ?
   AND UPPER(last_name) LIKE '%INA%'
```
のような、last_nameの条件がフィルタ述語にしかなりえないクエリに対しても、WHERE句の条件をインデックスに含めることで高速化する手段もある。  
```
CREATE INDEX empsubupnam ON employees
       (subsidiary_id, UPPER(last_name))
```

### LIKE検索
インデックスのツリー走査においてLIKEが有効なのは、最初のワイルドカードの前までだけ。  
残りの文字はスキャンされるインデックスの範囲を狭めてくれない、単なるフィルタ述語になる。  
LIKEが1つしかない表現には、(1) 最初のワイルドカードの前のアクセス述語として使われる部分、  
(2) フィルタ述語となるその他の部分、の2つの述語タイプのみがあり得ます。
  
ワイルドカードから始まるLIKE式もあり得るが、こういったLIKE式はアクセス述語としては使えない。  
そのためデータベースはテーブル全体をスキャンしなくてはならない。

### 部分インデックス
以下のクエリのようにWHERE句を使うことで部分的にインデックスを作成できる  
CREATE INDEX 〜 WHERE 条件;

### NULL
OracleではインデックスにNULL が含まれない。  
複合キーだと、どちらもNULLの場合にインデックスに含まれない。  
複合キーカラムA,Bがあり、WHERE A IS NULL;で検索するとき、「AあるいはBにNOT NULL制約」がある場合のみインデックスを使用した検索が実行される。  
※どちらもNULLの可能性が捨てきれない限り、インデックスに存在しないかもしれないのでテーブルフルスキャンしてしまう。  

### 処理しにくい条件
・日付型  
カラムに対して関数を使用しがちだが、関数インデックスを利用できないMySQLなどでは、BETWHEENの使用がおすすめ。  

・数値文字列  
```
SELECT ...
  FROM ...
 WHERE numeric_string = 42
```
のように引用符をつけ忘れると、暗黙的に  
```
SELECT ...
  FROM ...
 WHERE TO_NUMBER(numeric_string) = 42
```
となってしまうので気をつける。  
そもそも数値を保存する時は、数値型を使用する。  
また、逆の場合（数値型を文字列で検索）は、データベースが自動で変換するので問題ない。  

・バインドパラメータ  

```
SELECT first_name, last_name, subsidiary_id, employee_id
  FROM employees
 WHERE ( subsidiary_id    = :sub_id OR :sub_id IS NULL )
   AND ( employee_id      = :emp_id OR :emp_id IS NULL )
   AND ( UPPER(last_name) = :name   OR :name   IS NULL )
```
のような名前付きバインド変数を使った、フィルタを三つ用意したクエリがあったとする。  
ポイントはバインド変数にNULLを入れることで、フィルタを無効化できるところ。  
これがアンチパターンであり、オプティマイザはフィルタが３つとも無効化される最悪のパターンを想定するので、テーブルフルスキャンの実行計画を選択する。  

不要なフィルタは使用しないこと。  

・等式  
```
SELECT numeric_number
  FROM table_name
 WHERE numeric_number - 1000 > ?
```
```
SELECT a, b
  FROM table_name
 WHERE 3*a + 5 = b
```
のような等式を使ったクエリでは、関数インデックスと同じくインデックスを使用してくれない。  
関数インデックスを作成するか、以下のように定数を右辺に集めて、左辺に対するインデックスを作ればよい。  
```
CREATE INDEX math ON table_name (3*a - b)
```

### スケーラビリティ
```
SELECT count(*)
  FROM scale_data
 WHERE section = ?
   AND id2 = ?
```
のようなクエリを考える。sectionとid2の条件両方がアクセス述語になっていないと、データ量が増えるにつれクエリが遅くなってしまう。  
```
CREATE INDEX scale_slow ON scale_data (section, id1, id2)
```
というインデックスの場合、同じsectionはid1でソートされているため、同section内の、あるid2はまばらにリーフノードに存在する。  
そのためアクセス述語には使えず、フィルタ述語になってしまう。
```
CREATE INDEX scale_fast ON scale_data (section, id2, id1)
```
であれば、id2もアクセス述語になる。  

### 結合処理
3つのテーブル結合方式があるが、どれも同時に処理できるのは2つのテーブルまで。 つまり、3つ以上のテーブルを扱うSQLクエリは、まず最初に2つのテーブルを結合して中間テーブルを生成し、それからそれを次のテーブルと結合し…と いう処理を繰り返す。  

※  中間結果のパイプライン化
中間テーブルの各行はすぐにパイプライン化されて次の結合処理に渡され、これに よって中間結果の全体を保存する必要がない。  

関連する2テーブルに対する処理をする際に、N+1問題はORMを使用しているとついやってしまいがち。【参考】https://qiita.com/hisonl/items/763b9d6d4e90b1606635   
データベースアクセスが無駄に多いとパフォーマンスが落ちるので、結合を指示した1クエリで処理すること。  

3つの結合　http://www.atmarkit.co.jp/ait/articles/0408/25/news101.html   
・ハッシュ結合  
ハッシュ結合アルゴリズムは、入れ子ループ結合の、ネストループクエリを 実行する際にBツリー走査が大量発生してしまうという弱点に狙いを絞っている。  
・ソートマージ結合  http://use-the-index-luke.com/ja/sql/join/sort-merge-join  
ほぼ全てがハッシュ結合と同じだが、 1つだけソートマージ結合に特有なことがあります。それは、完全な対称性があること。  

### データクラスタ
クラスタには3種類ある。高性能クラスタ、フェイルオーバークラスタ、データクラスタ。  

データクラスタとは、少ないIO処理でアクセスできるように、連続的にアクセスされるデータを近くに保存すること。  
この技術はデータベースで利用されている。  

・ある行の全カラムを取得したいとき、一つのページ領域に全カラムのデータがあれば、ディスクアクセスの回数が減るためクエリは速くなる事を利用した、  
インデックスの順序に合わせて行を並び替える方法。  
※関連データがどれくらい複数ページに散らかっているかを示すクラスタ化係数というものがあり、オプティマイザが最適化の参考にする。  

・レコードデータ群に対するフィルタ述語になるカラムをインデックスに含める方法。  

・クエリに登場する全カラムをインデックスに含め、インデックススキャンのみのアクセスとする方法。  
※カバリングインデックスという。  

インデックスにデータを含めるとクエリが速くなることが多いが、MySQLのInnoDBでは、(全列の)キー長合計は3072バイトに制限されている。  
さらに、各列の長さはinnodb_large_prefixが有効になっていないか、行フォーマットにDYNAMICあるいはCOMPRESSEDが使用されていない場合は、767バイトに制限されている。  
※これはMySQL5.6以降ではデフォルト。  
MyISAMのインデックスは、16列までで、かつキーの最大長が1000バイトに制限されている。  

MySQLは、「プレフィックスインデックス」 (「部分インデックス」と呼ばれることもある)というユニークな機能があり、  
列の最初の数文字にだけインデックスを作ることができる。一方で部分インデックスはない。  

最大長を超えるインデックスを作ろうとすると、設定によってはその列を自動的に短くする。  
このような時には、create index文は 「Specified key was too long; max key length is ... bytes」という 警告を出しつつも成功してしまう。  
つまり、インデックスは列の完全なコピーではなくなってしまい、この列を選択する際もインデックスのみのスキャンに使えなくなってしまうので注意。  

明示的にキーの長さを指定してインデックスを作ることも可能。  
以下はLAST_NAME列の最初の10文字にのみインデックスを作る例。  
```
CREATE INDEX .. ON employees (last_name(10))
```

索引構成表（クラスタインデックス）について★重要  

データベースでは、一次的なテーブルデータの保存先として ページではなくインデックスを使用できる。  
このインデックスを、索引構成表（Oracle）もしくは、クラスタインデックスという。  

クラスタインデックスは、テーブルの主キー（クラスタリングキー）のインデックスとなっており、リーフノードに全カラムデータが入っている。  
そのため全てのクエリがインデックススキャンのみのアクセスとなり高速。  

ページ内（ヒープテーブル）のカラムデータを取得する流れは  
```
Bツリーインデックスを検索しポインタ取得(INDEX RANGE SCAN) ⇒ ポインタでヒープテーブルにアクセスし取得（TABLE ACCESS BY INDEX ROWID）
```
クラスタインデックスのカラムデータを取得する流れは  
```
セカンダリインデックスを検索しクラスタリングキー取得(INDEX RANGE SCAN) ⇒ クラスタリングキーでクラスタインデックスを検索しリーフノード取得(INDEX UNIQUE SCAN)
```
となる。クラスタインデックスの場合は2回インデックスにアクセスすることになる。  

※テーブルデータの保存方法としてヒープテーブルを利用しているのなら、そのインデックスをBツリーインデックスと呼び、  
クラスタインデックスを利用しているのなら、セカンダリインデックスと呼んでいる。（セカンダリインデックスも構造はBツリー）  

Bツリーインデックスと、セカンダリインデックスの違いは、  
セカンダリインデックスには指定していなくてもテーブルの主キーが含まれていることと、ポインタではなくクラスタリングキーを持っていることだけ。  

セカンダリインデックスにテーブル行への直接のポインタがあった方が好ましいが、それは行が保存してあるストレージ上の場所が変化しない場合にのみ可能。  
残念ながら、行がインデックスの一部であり順番を正しく保つために、行を逐一動かす必要があるクラスタインデックスでは不可能。  
例えば、 insert句は新しいエントリ用に空き容量を確保するため、リーフノードを分割することがあり、いくつかのエントリは違う場所の新しいデータブロックに移動されることになる。  

一方でヒープテーブルを使う場合、行を順番に並べておく必要はない。  
データベースは空いているページがありさえすればどこにでも新しいエントリを保存する。一度書き込まれたら、ページ内ではそのデータは移動しない。  

セカンダリインデックス検索後、クラスタインデックスを検索するのは非常に非効率である。そのためセカンダリインデックスに必要なカラムを含めて  
クラスタインデックスにアクセスしないようにする手段がある。  
ポイントはセカンダリインデックスには暗黙的にテーブルの主キーが含まれていることを忘れないこと。  

テーブルデータを、ページ（ヒープテーブル）とクラスタインデックスのどちらで保存すべきかは利用状況による。  
MySQLでは、MyISAMエンジンではヒープテーブル、InnoDBエンジンは常にクラスタインデックスを使う。  
  
### ソート処理
ソート処理は、一時的にソート結果を全てバッファしておく必要があるため、非常にリソースを消費する処理である。  
※ソートするのだから全データを集めた後ソートキーを並び変える必要があるため。  

インデックスのあるカラムでソートする場合、感覚ではソート済みのインデックスを利用することで最適化されそうだが、  
大量データに対するINDEX RANGE SCANと、それに続くTABLE ACCESS BY INDEX ROWIDの組み合わせは効率が悪く、明示的なソートをするFULL TABLE SCANの方が、場合によっては高速となる。  

しかし、インデックスを使ってorder byを実行する良い点として、ソート処理をしない事だけではなく、  
入力されたデータを全て処理する前に最初の結果を返してしまえる点がある。※パイプライン化という。  

インデックスを使ってorder byを実行するために、インデックスにカラムを追加する選択肢もあるが、クラスタ係数が悪くなることに注意しなければならない。  
カラム追加前インデックス（1カラムとする）ではキーでソートされているのはもちろん、第2ソートキーがrowidになっている。  
つまりINDEX RANGE SCAN後のTABLE ACCESS BY INDEX ROWIDするデータが近くに固まるためクラスタ係数が良くなっているが、  
2カラム目を追加することでrowidが第3ソートキーになり、クラスタ係数は悪くなってしまう。  

インデックスの第2キーでソートしたい場合、WHERE句で第1キーを一意に決定しているならばデータベースは明示的なソート処理をする必要が無くなるが、  
一意に決まらないと第2キーでソートされたデータを取得できない。  
【参考】http://use-the-index-luke.com/ja/sql/sorting-grouping/indexed-order-by  

パイプライン処理を期待していても、データベースがソート処理を行ってしまう場合、  

(1) 明示的なソートがあった方がコスト値が低い  

(2) スキャンされるインデックスの範囲のインデックス順序がorder by句に対応していない  

という2つの理由があり得る。  

(1)になるのは、オプティマイザが結果の最後のレコードを最も早く得られる実行計画を選ぶ場合があるため。  
 
データベースはインデックスをどちらの方向からも読むことが出来る。  
DESCを付けた場合は、INDEX RANGE SCANがリーフノードを下から上に向かって処理する。  

しかし  
```
ORDER BY sale_date ASC, product_id DESC
```
のような、一部のカラムが逆順になると、リーフノードをジャンプする必要があり、処理できない。  

こういうときは、この順序を持つインデックスを作成すればよい。  
```
CREATE INDEX sales_dt_pr
    ON sales (sale_date ASC, product_id DESC)
```
※バージョン5.7までのMySQLでは、インデックス定義時の ASCやDESC修飾語を無視する。  

これまでの説明の通り、Bツリーインデックスではインデックスの全カラムを逆順に読むときは特に特別な操作は必要ない。  
しかしセカンダリインデックスの場合、暗黙的にリーフノードがクラスタリングキー順にソートされているため、  
セカンダリインデックスからインデックスカラムとクラスタリングキーを逆順で出力したい場合は、インデックスカラムを逆順に登録しておかなければならない。  

NULLのソート順について  
データベースにより様々  
【参考】http://use-the-index-luke.com/ja/sql/sorting-grouping/order-by-asc-desc-nulls-last  

### グルーピング処理
データベースでは2種類のgroup byアルゴリズムが提供される。  

(1)ハッシュアルゴリズム... 対象レコード群の全てを一時的なハッシュテーブル上でまとめ上げ結果として返却する。    
(2)ソート・グループアルゴリズム... 対象レコード群をグループキーでソートし、各グループを順番に処理できるようにした後、データベースがまとめる。    

基本的にどちらも中間結果をマテリアライズする必要があるので、パイプライン的に処理されないが    
ソート・グループアルゴリズムにおいてグループキーのインデックスが存在する場合、明示的なソートは不要となり、ソート処理と同じくパイプライン化されたgroup byとして実行される。    

パイプライン化されたgroup byを利用できるかどうかは、パイプライン化したソート処理の利用条件と同じである。  

パイプライン化されたgroup byを利用できない場合、    
ハッシュアルゴリズムの利点は、1行ずつ処理し、まとめられた結果だけをバッファすれば良い一方で  
ソート・グループアルゴリズムは全行をマテリアライズするため、メモリ使用量からハッシュアルゴリズムの方が使われる。  
  
### 部分結果  
最初のN行のみの結果が欲しいとき、パイプライン化したソート処理が利用できるならば、N行をTABLE ACCESS BY INDEX ROWIDするだけでよい。  
しかしオプティマイザはそれに気付かないので明示的に指定する必要がある。  
```
SELECT *
  FROM sales
 LIMIT 10
```
では気付かないから
```
SELECT *
  FROM sales
 ORDER BY sale_date DESC
 LIMIT 10
```
とする。 
  
前者であっても「LIMIT 10」を付けることで10行分だけマテリアライズするだけで済むようになる。    

次の10件を取得する(ページング処理)場合、2つの方法がある。  
(1)オフセット法  
(2)シーク法  
  
オフセット法  
```
SELECT *
  FROM sales
 ORDER BY sale_date DESC
 LIMIT 10 OFFSET 10
```
のように指定することで最初の10行を飛ばして読み込める。欠点としては  
今まで読み込んだ行数を覚えておく必要があること  
新しい行が追加されると表示がずれること  
データベースは上記であれば20件読み込んで10件分表示しているだけなので、件数に比例して遅くなること  
があげられる。  

シーク法
```
SELECT *
  FROM sales
 WHERE sale_date < ?
 ORDER BY sale_date DESC
 LIMIT 10
```
のように、次10件の最初に来るべき条件をWHERE句に入れる。  
この欠点は、最初の10件の最後のsale_dateに重複があり、11件目にも同じsale_dateがある場合に、11件目のデータが破棄されてしまうこと。    
これからわかるようにページング処理では、ソートキーに重複がある場合は注意が必要。    

しかも同じソートキーは順番が一意に定まらないため、それも不具合の原因となりやすい。    
そういう場合は別のソートキーを追加し、順番が一意になるようにする。    

一意に定まるようにsale_idをインデックスに追加したとすると、
```
WHERE (sale_date, sale_id) < (?, ?)
```
のようなクエリでシーク法を実現できる。上記の書き方は「行値式」といいSQL標準機能だが、サポートしているデータベースは少ない。  
※MySQLは「行値式」を認識してくれるが、インデックスアクセス時のアクセス述語としては使えない。  

行値式について  
通常のスカラ値に対して、行の値を括弧内に列挙したものを行値という。  
よくINSERT文で利用されている。  

2つの行値Rx,Ryの比較は以下のルールになっている  
```
Rx < Ry" is true if and only if RXi = RYi for all i < n and RXn < RYn for some n.
訳）全てのi < nでRXi = RYiかつ、あるnに対しRXn < RYnの時、かつその時に限り、Rx < Ryは真となる。

(5,10) > (4,11)で、(5,10) < (5,11)
```

行値式を使えないMySQLで、シーク法を利用したい場合は、
```
WHERE sale_date <= ?
 AND NOT (sale_date = ? AND sale_id >= ?)
```
とする。こうすると、最初の「sale_date <= ?」をアクセス述語とし、そこから残りのフィルタ述語を適用してくれる。  
ORを使って以下のようにも書ける。
```
WHERE (
         (sale_date < ?)
       OR
         (sale_date = ? AND sale_id < ?)
      )
```
が、ORを使用すると、それぞれの条件をフィルタ述語としてしまうので使ってはいけない。  

### データの変更 
##### 挿入(insert)
・ページ(ヒープテーブル)の場合  
行データの挿入... 空いているページに追加する。  
インデックス更新... インデックスにアクセスして挿入すべきリーフノードを決定し、空きがあれば挿入、なければインデックスを分割する。  

インデックスが少ない方がパフォーマンスが向上する。  

・クラスタインデックスの場合  
##### 削除(delete)
基本的にはinsertと同じで、インデックスが少ない方がパフォーマンスが向上するが、WHERE句で指定したカラムのインデックスがないと  
削除対象レコードを見つけるためにフルテーブルスキャンしてしまい、むしろパフォーマンスが落ちる可能性がある点は異なる。  

当然WHERE句のないdelete文は、インデックスを使えない。  
その場合通常は、代わりに専用のSQLコマンドであるtruncate tableを使用する。  
このコマンドは、一度に全行を削除する点を除いてwhere句のないdelete文と同じ効果を持つが、  
(1) 暗黙的にcommitが実行される、(2) トリガが実行されない、という2つの副作用もある。

##### 更新(update)
update文が実行されると、更新された列を含むインデックスの順序を維持する必要がある。  
その時データベースの動作としては、インデックスの古いエントリを削除して、新しいエントリを挿入する。  

つまり処理内容はほぼdeleteしてinsertした時を同じになる。  
唯一の違いは更新された列を含むインデックスしか更新する必要がないということ。  

そのことから、updateのパフォーマンスを向上させるには、必要な列のみ更新することが大事だが、  
ORMツールでは意図せず全列更新してしまう場合があるので注意する。  

### 実行計画（どの物理プランを使うか検討する）  
論理プラン中の関係代数演算「選択」を、物理プラン中ではインデックススキャンモジュールにするか、フルスキャンモジュールにするかが主な要因となる。  
また、WHERE句の条件がアクセス述語とフィルタ述語のどちらになっているかも重要。

選択された実行計画はEXPLAIN で出力できる  

一番重要なのは ***「TYPE列」***  

以下、MySQLの例  

***・インデックスの使用状況の観点***  
---
##### TYPE列... データがどのようにアクセスされるかを示すもので、個人的には「アクセスタイプ」のようなイメージ
- `eq_ref, const`  
「INDEX UNIQUE SCAN」した後、必要なら追加でテーブルから列を取り出す(「TABLE ACCESS BY INDEX ROWID」)  
プライマリーキーや一意制約により、インデックス検索条件が2件以上にマッチしない。  
- `ref, range`  
「INDEX RANGE SCAN」した後、必要なら追加でテーブルから列を取り出す(「TABLE ACCESS BY INDEX ROWID」)  
- `index`  
インデックスの全行を、インデックスの順に沿って読み出す(INDEX FULL SCANと似ている)。  
INDEX FULL SCANは、カタログに基づき、インデックス全行をその順に取り出す必要があると判断した時に実行される。  
- `ALL`  
テーブル全体をディスクに保存されている通りに読み込む(フルテーブルスキャン)。  
その後全行のカラムデータを読み出す必要があるので
IO時間とCPU時間の両方で負担が大きい。  
- `index_merge`  
複数の「INDEX RANGE SCAN」結果をマージしている。  

##### Extra列... 追加情報を表示する。  
- `Using Index`  
インデックスに必要なデータが揃っているのでテーブルアクセスしない。  
クラスタインデックスをプライマリーキーで検索する際は、理論的には同じだが、この表示はない。  

- `Using intersect(インデックス名,インデックス名)`  
TYPE列がindex_mergeの際に、どのインデックスのスキャン結果をマージしたか表示する。  

##### key列 または possible_keys列... 実際に使用したインデックス名(key), 使用可能なインデックス名(possible_keys)を表示する。
- `PRIMARY`  
プライマリーキーに自動的に作成されるインデックスを指す。  

##### ref列... インデックスを利用する場合に、インデックスに対して比較するカラム名(定数の場合const、関数の場合func)がカンマ区切りで表示される。  
```
例) 「const,const」と表示される場合、1つのインデックスから2カラム利用されていることが分かる。  
```

***・ソートとグルーピングの観点***  
---
##### Extra列
- `using filesort`  
データベースが明示的なソートを実施する。  
ソート処理がメモリ・ディスクのどちらで実施されているかは不明だが、どちらにせよ中間結果をマテリアライズ化するため非常に多くのメモリを必要とする。  
この表示がない場合は、パイプライン化されたソート処理となる。  

***・アクセス述語とフィルタ述語の見分け方***  
---
##### Key_len列... インデックスを利用する場合に、インデックスのキーをどれくらい利用するか表示する。
```
例) 「12」の場合、インデックスのキーを12バイトを利用している。
インデックスがNUMERIC型の3列で構成されている場合、NUMERIC型は1列6バイトであるので、インデックスの1,2列目を利用していることがわかる。  

また、この表示があると、ref列の値がアクセス述語として利用されている。  
【データ型のサイズ】https://dev.mysql.com/doc/refman/5.6/ja/storage-requirements.html
```

##### Extra列
- `Using index condition`  
インデックスのリーフノードに対するフィルタ述語(インデックスフィルタ述語)となる。  
- `Using where`  
テーブルデータに対するフィルタ述語(テーブルレベルフィルタ述語)となる。　　

詳細はMySQLのマニュアルで確認する。https://dev.mysql.com/doc/refman/5.6/ja/execution-plan-information.html  

***・経験からポイントをまとめていく***  
---
- 結合について  
MySQLはネストループ結合アルゴリズムしか利用しないのでわかりやすいが、結合の**順序**に注意する。  
SQL文に出てくる順番は関係なく、EXPLAINの出力行の上から順に結合処理が進んでいく。  
【参考】http://d.hatena.ne.jp/LukeSilvia/20090501/p1  

- EXPLAINのid列について  
id列とselect_type列はセットで考えると良い。  
【参考】http://nippondanji.blogspot.jp/2009/03/mysqlexplain.html  

- プライマリーキーで範囲検索（大なり）したのにExtra列が「Using where」  
innodbだからクラスタインデックスをクラスタリングキーで検索していて、Using where(テーブルレベルフィルタ述語)はでないのでは？  
↓  
クラスタインデックスの場合、連続したデータに見えても、実際のディスクアクセスはランダムアクセスとなる。(プライマリーキーに変更があるとインデックス順序保持のためにデータが移動するから)  
【参考】http://use-the-index-luke.com/ja/sql/clustering/index-organized-clustered-index  
この読み取りをMySQLの世界では歴史的に「Random Read」という。  
↓  
つまり、プライマリーキーで一意に決まったレコードを、全てランダムアクセスするよりも、効率重視で無駄なデータがあってもよいから
シーケンシャルアクセスし、その時混ざったゴミをフィルタしている可能性がある。  
↓  
ディスクアクセスの状況はセッションステータスを確認する。  
`SHOW SESSION STATUS LIKE 'Handler\_%';`  
【参考】https://www.infiniteloop.co.jp/blog/2012/03/mysql-tuning-cacti-query/  
以下、「Using where」が出る例
```
mysql> EXPLAIN SELECT * FROM product WHERE プライマリーキー > ****;
+----+-------------+-------------+-------+-------------------------+---------+---------+-------+------+-----------+
| id | select_type | table       | type  | possible_keys           | key     | key_len | ref   | rows | Extra     |
+----+-------------+-------------+-------+-------------------------+---------+---------+-------+------+-----------+
|  1 | SIMPLE      | product     | range | *************           | PRIMARY | *       | NULL  |  *** |Using where|
+----+-------------+-------------+-------+-------------------------+---------+---------+-------+------+-----------+
```


- 統計情報が間違っている可能性  
```
# 統計情報更新
ANALYZE TABLE tra_product;
# セッションステータスをフラッシュ
FLUSH STATUS;
# クエリ実行
SELECT～
# セッションステータス確認
SHOW SESSION STATUS LIKE 'Handler\_%';

このHandler～ステータスから、実際にテーブルやインデックスから何行読みとったか等が分かる。
【参考】https://www.infiniteloop.co.jp/blog/2012/03/mysql-tuning-cacti-query/
```









# ・トランザクション  
トランザクションを開始すると、ロールバック用の情報を保存するためディスク領域の一部を，そのトランザクションに対して割り当てます。この領域をロールバック・セグメントと呼びます。  
流れは以下  
トランザクション開始  
↓  
レコードの追加や更新などの変更を行うたびに、そのレコードを含むページの（変更前の）内容をロールバック・セグメント（メモリ上）に保存する  
↓  
REDOログ・バッファに変更の履歴を記録する。※REDOログ・バッファは，変更の履歴を記録しておくためのメモリー上のバッファで，後でディスク上のREDOログ・ファイルに内容が保存されます。  
↓  
ページの内容を更新する  
↓  
トランザクションをコミット  
↓  
トランザクションに対して、識別するための「システム変更番号（SCN）」を割り当て  
↓  
ロールバック・セグメント（メモリ上）にこの番号とコミット済みであることを記録  
↓  
REDOログ・バッファの内容を，REDOログ・ファイル（ディスク）に書き出す（メモリ上に持ったままだと、ここでシステムダウンしたとき、ロールバックセグメントとREDOログデータの両方を失ってしまう）  
↓  
トランザクション完了  
↓  
適当なタイミングでロールバック・セグメント（メモリ上）のデータをディスクに書き出す。  
詳細 http://itpro.nikkeibp.co.jp/article/COLUMN/20060118/227489/  
  
# ・ロックについて  
上記のトランザクションは、あくまで一人のユーザーに焦点を当てたものであり、マルチユーザーでの複数のトランザクション間制御では、「ロック」という技術が使われる  
「ロック」には以下の3種類がある  
排他ロック... レコードを更新・削除するために取得するロック。レコードに対して一つのプロセスしか取得できず、他のプロセスは読み込みや変更が出来ない。  
共有ロック... レコードを読み込むために取得するロック。レコードに対して複数のプロセスが取得可能。共有ロックがかかっているレコードには排他ロックは取得できない。  
範囲ロック... レコードを読み込むために取得するロック。特定のキーの値の範囲を共有ロックすることで、その段階ではまだ存在しないキーのINSERT・DELETEを防ぐ。  
わかりやすく言えば、  
共有ロックは、１トランザクションで読み込み結果が変わるかどうかに関係する  
排他ロックは、上記で読み込み結果が変わる場合、どのくらい変わるか※に関係する  
※他トランザクションの未コミット変更結果が参照される未コミットレベル、他トランザクションのコミット済み変更結果が参照されるコミットレベル、他トランザクションのインサート結果が参照されるインサートレベルとする（勝手に決めた）  
  
トランザクション中の各処理（読み込みや書き込み）において、この2種類のロックの使い方（ルール）を決める。  
ルール１... 読み込み：ロック無し　　書き込み：ロック無し  
ルール２... 読み込み：ロック無し　　書き込み：排他ロック  
ルール３... 読み込み：共有ロック　　書き込み：排他ロック  
ルール４... 読み込み：範囲ロック　　書き込み：排他ロック  
RDBMSは上記のどれかのルールを採用する。デフォルトはルール２。ルールはトランザクション分離レベルともいわれる。  
【ルール１：READ UNCOMMITTED分離レベル】  
読み込み結果が未コミットレベルで変わる  
  
読み込み... 対象レコードをロックしないので、他トランザクションは更新できる(読み込み結果が変わる)  
書き込み... 対象レコードをロックしないので、他トランザクションは未コミットの結果を参照・更新できる  
【ルール２：READ COMMITTED】  
読み込み結果がコミットレベルで変わる  
  
読み込み... 対象レコードをロックしないので、他トランザクションは更新できる(読み込み結果が変わる)  
書き込み... 対象レコードを排他ロックするので、他トランザクションは未コミットの結果は参照・更新出来ないが、コミットした結果はできる  
【ルール３：REPEATABLE READ】  
読み込み結果がインサートレベルで変わる  
  
読み込み... 対象レコードを共有ロックするので、他トランザクションは更新できない(読み込み結果が変わらないが、増える)  
書き込み... 対象レコードを排他ロックするので、他トランザクションは未コミットの結果は参照・更新出来ないが、コミットした結果はできる  
※共有ロックはレコードに対して行われるので、その段階でまだ存在しないレコードはロックされておらず、インサートは可能  
そのため、読み込みで範囲指定していた場合、急にレコードが増えたりする。  
【ルール４：SERIALIZABLE】  
読み込み結果が変わらない  
  
読み込み... 対象レコードを範囲ロックするので、他トランザクションは範囲内の更新・削除・挿入ができない(読み込み結果が変わらない）  
書き込み... 対象レコードを排他ロックするので、他トランザクションは未コミットの結果は参照・更新出来ないが、コミットした結果はできる  
  
【特別ルール】  
読み込みで、共有、範囲ロックをしてしまうと、他のトランザクションで更新・削除・挿入ができないため不便である。  
そのため読み込みではロックをしない実装もある。  
その場合、まずデータを読み込む際にそのデータのSCNを調べ、データの内容がトランザクション開始以降に更新されている場合には  
ロールバック・セグメントから更新前のデータを取り出して読み込む。  
そうすれば共有、範囲ロックすることなく、１トランザクションで読み込み結果が変わらない  
詳細 http://itpro.nikkeibp.co.jp/article/COLUMN/20060118/227489/?SS=imgview&FD=3561930  
  
  
  
